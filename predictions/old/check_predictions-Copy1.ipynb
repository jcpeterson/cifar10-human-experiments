{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, gc\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy as scent\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import collections\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def ent_fn(X):\n",
    "    \"\"\"Return row-wise entropy of X (samples by probs)\"\"\"\n",
    "    ents = np.empty(X.shape[0])\n",
    "    for i, row in enumerate(X):\n",
    "        ents[i] = scent(row)\n",
    "    return ents\n",
    "\n",
    "loadDir = 'base_predictions'\n",
    "\n",
    "# raw bins\n",
    "bins = np.load('{0}/human_bincounts.npy'.format(loadDir))\n",
    "\n",
    "#raw probabilities\n",
    "humans = bins / np.sum(bins, axis = 1)[:, np.newaxis]\n",
    "\n",
    "# smoothed probabilities\n",
    "humans_smoothed = (bins +1) / np.sum(bins, axis = 1)[:, np.newaxis]\n",
    "\n",
    "ordered_filenames = np.load('{0}/decoded_test_filename_order.npy'.format(loadDir))\n",
    "\n",
    "labels = ['P', 'A', 'B', 'C', 'De', 'Do', 'F', 'H', 'S', 'T']\n",
    "\n",
    "im_dir = '/home/battleday/Academic/Berkeley/Superman/local/images/train_set_combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vgg_15_BN_64_train.npz', 'resnet_basic_110_train.npz', 'resnet_preact_bottleneck_164_train.npz', 'shake_shake_26_2x64d_SSI_cutout16_train.npz', 'densenet_BC_100_12_train.npz', 'wrn_28_10_train.npz', 'resnext_29_8x64d_train.npz', 'pyramidnet_basic_110_270_train.npz']\n",
      "['densenet_BC_100_12_train.npz', 'pyramidnet_basic_110_270_train.npz', 'resnet_basic_110_train.npz', 'resnet_preact_bottleneck_164_train.npz', 'resnext_29_8x64d_train.npz', 'shake_shake_26_2x64d_SSI_cutout16_train.npz', 'vgg_15_BN_64_train.npz', 'wrn_28_10_train.npz']\n",
      "['resnext_29_8x64d_test.npz', 'resnet_preact_bottleneck_164_test.npz', 'densenet_BC_100_12_test.npz', 'vgg_15_BN_64_test.npz', 'pyramidnet_basic_110_270_test.npz', 'wrn_28_10_test.npz', 'shake_shake_26_2x64d_SSI_cutout16_test.npz', 'resnet_basic_110_test.npz']\n",
      "['densenet_BC_100_12_test.npz', 'pyramidnet_basic_110_270_test.npz', 'resnet_basic_110_test.npz', 'resnet_preact_bottleneck_164_test.npz', 'resnext_29_8x64d_test.npz', 'shake_shake_26_2x64d_SSI_cutout16_test.npz', 'vgg_15_BN_64_test.npz', 'wrn_28_10_test.npz']\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir('{0}/train/'.format(loadDir))\n",
    "print(train_files)\n",
    "train_files = sorted([m for m in train_files if m[-4:] == '.npz'])\n",
    "print(train_files)\n",
    "\n",
    "test_files = os.listdir('{0}/test/'.format(loadDir))\n",
    "print(test_files)\n",
    "test_files = sorted([p for p in test_files if p[-4:] == '.npz'])\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels', 'logits', 'probs']\n",
      "(50000, 10) (50000, 10)\n",
      "(50000,)\n",
      "50000\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "De\n",
      "B\n",
      "P\n",
      "A\n",
      "P\n",
      "B\n",
      "F\n",
      "T\n",
      "A\n",
      "A\n"
     ]
    }
   ],
   "source": [
    "# test one output to prob\n",
    "test = np.load('{0}/train/{1}'.format(loadDir, train_files[4]))\n",
    "\n",
    "print(test.keys())\n",
    "print(test['logits'].shape, test['probs'].shape)\n",
    "guess = np.argmax(test['probs'], axis = 1)\n",
    "print(guess.shape)\n",
    "print(np.sum(test['labels'] == guess))\n",
    "\n",
    "for i in [0, -1]:\n",
    "    out = test['logits'][i, :]\n",
    "    probs = test['probs'][i, :]\n",
    "    soft = softmax(out)\n",
    "    print(np.abs(probs-soft)<0.001)\n",
    "\n",
    "for l in test['labels'][-10:]:\n",
    "    print(labels[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['densenet_BC_100_12_train', 'pyramidnet_basic_110_270_train', 'resnet_basic_110_train', 'resnet_preact_bottleneck_164_train', 'resnext_29_8x64d_train', 'shake_shake_26_2x64d_SSI_cutout16_train', 'vgg_15_BN_64_train', 'wrn_28_10_train'])\n"
     ]
    }
   ],
   "source": [
    "train_dict = collections.OrderedDict()\n",
    "for m in train_files:\n",
    "    raw = np.load('{0}/train/{1}'.format(loadDir, m))\n",
    "    model = m.split('.')[0]\n",
    "    train_dict[model] = {}\n",
    "    for prop in raw.keys(): \n",
    "        train_dict[model][prop] = raw[prop]\n",
    "    train_dict[model]['entropy'] = ent_fn(train_dict[model]['probs'])\n",
    "print(train_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['densenet_BC_100_12_test', 'pyramidnet_basic_110_270_test', 'resnet_basic_110_test', 'resnet_preact_bottleneck_164_test', 'resnext_29_8x64d_test', 'shake_shake_26_2x64d_SSI_cutout16_test', 'vgg_15_BN_64_test', 'wrn_28_10_test'])\n"
     ]
    }
   ],
   "source": [
    "test_dict = collections.OrderedDict()\n",
    "for m in test_files:\n",
    "    raw = np.load('{0}/test/{1}'.format(loadDir, m))\n",
    "    model = m.split('.')[0]\n",
    "    test_dict[model] = {}\n",
    "    for prop in raw.keys(): \n",
    "        test_dict[model][prop] = raw[prop]\n",
    "    test_dict[model]['entropy'] = ent_fn(test_dict[model]['probs'])\n",
    "print(test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "averageEnt = []\n",
    "for key, value in train_dict.items():\n",
    "    averageEnt.append(value['entropy'])\n",
    "averageEnt = np.mean(averageEnt, axis=0)\n",
    "print(averageEnt.shape)\n",
    "\n",
    "num_ims = 5\n",
    "top = np.argsort(averageEnt)[::-1]\n",
    "print(top.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fig_fn(title, save_path, ims, \n",
    "           num_ims, added_rows, bolded_axes,\n",
    "           base_rows = 7):\n",
    "    \"\"\"still a bunch of other things defined above\n",
    "    that aren't in here\"\"\"\n",
    "    extended_ims = ims.copy()[-(num_ims * (added_rows -1)):]\n",
    "    ims = ims.copy()[-num_ims:]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=((num_ims) * 2, added_rows + base_rows)) \n",
    "    gs = gridspec.GridSpec(added_rows + base_rows, num_ims)\n",
    "\n",
    "    for i in np.arange(num_ims * (added_rows - 1)):\n",
    "        r, c = np.unravel_index(i, (added_rows - 1, num_ims))\n",
    "        #print(r, c)\n",
    "        ax = plt.subplot(gs[r, c])\n",
    "        im = extended_ims[i]\n",
    "        im_name = ordered_filenames[im]\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        img = mpimg.imread(im_dir + '/' + im_name)\n",
    "        #ax_im_b.set_title('High certainty image', fontsize = 20)\n",
    "        ax.imshow(img)\n",
    "\n",
    "\n",
    "    fig.suptitle(title, fontsize = 20, fontweight='bold')\n",
    "    for i in np.arange(num_ims):\n",
    "        im = ims[i]\n",
    "        ax_im_b = plt.subplot(gs[added_rows:3 + added_rows, i]) # size of im\n",
    "        im_name_b = ordered_filenames[im]\n",
    "        ax_im_b.xaxis.set_ticklabels([])\n",
    "        ax_im_b.set_xticks([])\n",
    "        ax_im_b.set_yticks([])\n",
    "        #ax_im_b.set_title(labels[0], fontsize = 12)\n",
    "        ax_im_b.yaxis.set_ticklabels([])\n",
    "        img_b = mpimg.imread(im_dir + '/' + im_name_b)\n",
    "        #ax_im_b.set_title('High certainty image', fontsize = 20)\n",
    "        ax_im_b.imshow(img_b)\n",
    "\n",
    "\n",
    "        im_guesses = humans[im]\n",
    "        #print(im_guesses)\n",
    "        ax_hist_b = plt.subplot(gs[added_rows + 3, i])\n",
    "        ax_hist_b.bar(np.arange(10), im_guesses) #, align = 'left')\n",
    "        ax_hist_b.set_xlim([-1, 10])\n",
    "        ax_hist_b.set_ylim([0, 1]) \n",
    "\n",
    "        if ax_hist_b.is_first_col():\n",
    "            if 0 in bolded_axes:\n",
    "                ax_hist_b.set_ylabel('Human Pr', fontsize = 12, fontweight = 'bold')\n",
    "            else:\n",
    "                ax_hist_b.set_ylabel('Human Pr', fontsize = 12)\n",
    "                # set to count\n",
    "        #ax_hist_b.set_xlabel('Category', fontsize = 24) # set to count\n",
    "        else:\n",
    "            ax_hist_b.yaxis.set_ticks([])\n",
    "\n",
    "        ax_hist_b.xaxis.set_ticks([])\n",
    "\n",
    "\n",
    "        im_guesses = NN[im]\n",
    "        #print(im_guesses)\n",
    "        ax_hist_n = plt.subplot(gs[added_rows + 4, i])\n",
    "        ax_hist_n.bar(np.arange(10), im_guesses) #, align = 'left')\n",
    "        ax_hist_n.set_xlim([-1, 10])\n",
    "        ax_hist_n.set_ylim([0, 1]) \n",
    "\n",
    "        if ax_hist_n.is_first_col():\n",
    "            if 1 in bolded_axes:\n",
    "                ax_hist_n.set_ylabel('NN Pr', fontsize = 12, fontweight = 'bold') \n",
    "            else: \n",
    "                ax_hist_n.set_ylabel('NN Pr', fontsize = 12) \n",
    "                    # set to count\n",
    "        else:\n",
    "            ax_hist_n.yaxis.set_ticks([])\n",
    "        ax_hist_n.xaxis.set_ticks([])\n",
    "        #ax_hist_n.xaxis.set_ticks(np.arange(10))\n",
    "\n",
    "        im_guesses = PT[im]\n",
    "\n",
    "        #print(im_guesses)\n",
    "        ax_hist_p1 = plt.subplot(gs[added_rows + 5, i])\n",
    "        ax_hist_p1.bar(np.arange(10), im_guesses) #, align = 'left')\n",
    "        ax_hist_p1.set_xlim([-1, 10])\n",
    "        ax_hist_p1.set_ylim([0, 1]) \n",
    "\n",
    "        if ax_hist_p1.is_first_col():\n",
    "            if 2 in bolded_axes:\n",
    "                ax_hist_p1.set_ylabel('PT Pr', fontsize = 12, fontweight = 'bold') \n",
    "            else:\n",
    "                ax_hist_p1.set_ylabel('PT Pr', fontsize = 12)\n",
    "                # set to count\n",
    "        else:\n",
    "            ax_hist_p1.yaxis.set_ticks([])\n",
    "\n",
    "        #ax_hist_n.xaxis.set_ticks(np.arange(10))\n",
    "        ax_hist_p1.xaxis.set_ticks([])\n",
    "\n",
    "        im_guesses = EX[im]\n",
    "        #print(im_guesses)\n",
    "        ax_hist_p2 = plt.subplot(gs[added_rows + 6, i])\n",
    "        ax_hist_p2.bar(np.arange(10), im_guesses) #, align = 'left')\n",
    "        ax_hist_p2.set_xlim([-1, 10])\n",
    "        ax_hist_p2.set_ylim([0, 1]) \n",
    "\n",
    "        if ax_hist_p2.is_first_col():\n",
    "            if 3 in bolded_axes:\n",
    "                ax_hist_p2.set_ylabel('EX Pr', fontsize = 12, fontweight = 'bold') \n",
    "            else:\n",
    "                ax_hist_p2.set_ylabel('EX Pr', fontsize = 12) # set to count\n",
    "        else:\n",
    "            ax_hist_p2.yaxis.set_ticks([])\n",
    "\n",
    "        ax_hist_p2.xaxis.set_ticks(np.arange(num_ims))\n",
    "        ax_hist_p2.xaxis.set_ticklabels(labels)\n",
    "        plt.xticks(rotation = -45, ha='center')\n",
    "\n",
    "    plt.savefig(save_path + '/' + title + '.png')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
