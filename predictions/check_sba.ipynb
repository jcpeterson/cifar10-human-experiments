{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, gc\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from scipy.stats import pearsonr as pr\n",
    "\n",
    "import collections\n",
    "\n",
    "def sba(model_predictions, human_predictions):\n",
    "    \"\"\"Returns second best accuracy score (of wrong images)\"\"\"\n",
    "    total = model_predictions.shape[0]\n",
    "    right = 0\n",
    "    for i in np.arange(total):\n",
    "        msb = np.argsort(model_predictions[i])[-2] # takes second best\n",
    "        lab = np.argmax(human_predictions[i])\n",
    "        right += (msb == lab)\n",
    "    return right / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val idx shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "loadDir = 'base_predictions'\n",
    "postDir = 'post'\n",
    "saveDir = 'figures'\n",
    "# raw bins\n",
    "bins = np.load('{0}/human_bincounts.npy'.format(loadDir))\n",
    "#correct = np.argmax(bins, axis = 1)\n",
    "#print(correct[:5])\n",
    "#raw probabilities\n",
    "humans = bins / np.sum(bins, axis = 1)[:, np.newaxis]\n",
    "max_prob = np.max(humans, axis = 1)\n",
    "humans_correct = np.argmax(humans, axis = 1)\n",
    "humans_smoothed = (bins + 1) / np.sum(bins, axis = 1)[:, np.newaxis]\n",
    "\n",
    "validation_idx = np.load('./val_idx_seed_0.npy')\n",
    "print('val idx shape: ', validation_idx.shape)\n",
    "\n",
    "ordered_filenames = np.load('{0}/decoded_test_filename_order.npy'.format(loadDir))\n",
    "\n",
    "labels = ['P', 'A', 'B', 'C', 'De', 'Do', 'F', 'H', 'S', 'T']\n",
    "\n",
    "im_dir = '/home/battleday/Academic/Berkeley/Superman/local/images/train_set_combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.intersect1d(validation_idx, np.arange(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnext_29_8x64d_test.npz', 'resnet_preact_bottleneck_164_test.npz', 'densenet_BC_100_12_test.npz', 'vgg_15_BN_64_test.npz', 'pyramidnet_basic_110_270_test.npz', 'wrn_28_10_test.npz', 'shake_shake_26_2x64d_SSI_cutout16_test.npz', 'resnet_basic_110_test.npz']\n",
      "['densenet_BC_100_12_test.npz', 'pyramidnet_basic_110_270_test.npz', 'resnet_basic_110_test.npz', 'resnet_preact_bottleneck_164_test.npz', 'resnext_29_8x64d_test.npz', 'shake_shake_26_2x64d_SSI_cutout16_test.npz', 'vgg_15_BN_64_test.npz', 'wrn_28_10_test.npz']\n",
      "['densenet_BC_100_12_test.npz', 'pyramidnet_basic_110_270_test.npz', 'resnet_basic_110_test.npz', 'resnext_29_8x64d_test.npz', 'shake_shake_26_2x64d_SSI_cutout16_test.npz', 'vgg_15_BN_64_test.npz', 'wrn_28_10_test.npz']\n",
      "odict_keys(['densenet_BC_100_12_test', 'pyramidnet_basic_110_270_test', 'resnet_basic_110_test', 'resnext_29_8x64d_test', 'shake_shake_26_2x64d_SSI_cutout16_test', 'vgg_15_BN_64_test', 'wrn_28_10_test'])\n"
     ]
    }
   ],
   "source": [
    "test_files = os.listdir('{0}/test/'.format(loadDir))\n",
    "print(test_files)\n",
    "test_files = sorted([p for p in test_files if p[-4:] == '.npz'])\n",
    "print(test_files)\n",
    "test_files.remove('resnet_preact_bottleneck_164_test.npz')\n",
    "print(test_files)\n",
    "\n",
    "test_dict = collections.OrderedDict()\n",
    "for m in test_files:\n",
    "    raw = np.load('{0}/test/{1}'.format(loadDir, m))\n",
    "    model = m.split('.')[0]\n",
    "    test_dict[model] = {}\n",
    "    for prop in raw.keys(): \n",
    "        test_dict[model][prop] = raw[prop]\n",
    "print(test_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['densenet_BC_100_12_test', 'pyramidnet_basic_110_270_test', 'resnet_basic_110_test', 'resnext_29_8x64d_test', 'shake_shake_26_2x64d_SSI_cutout16_test', 'vgg_15_BN_64_test', 'wrn_28_10_test'])\n"
     ]
    }
   ],
   "source": [
    "post_files = os.listdir('{0}/'.format(postDir))\n",
    "#print(post_files)\n",
    "post_files = sorted([p for p in post_files if p[-4:] == '.npz'])\n",
    "#print(post_files)\n",
    "\n",
    "post_dict = collections.OrderedDict()\n",
    "for m in post_files:\n",
    "    raw = np.load('{0}/{1}'.format(postDir, m))\n",
    "    model = m.split('.')[0]\n",
    "    post_dict[model] = {}\n",
    "    for prop in raw.keys(): \n",
    "        post_dict[model][prop] = raw[prop]\n",
    "print(post_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet_BC_100_12_test\n",
      "validation idx overlap with wrong idx human:  (39,)\n",
      "validation idx overlap with wrong idx labels:  (39,)\n",
      "num errors: (456,) accuracy:  0.9544\n",
      "sba:  0.668859649123\n",
      "validation sba:  0.74358974359\n",
      "validation accuracy:  0.961\n",
      "pyramidnet_basic_110_270_test\n",
      "validation idx overlap with wrong idx human:  (34,)\n",
      "validation idx overlap with wrong idx labels:  (34,)\n",
      "num errors: (397,) accuracy:  0.9603\n",
      "sba:  0.659949622166\n",
      "validation sba:  0.617647058824\n",
      "validation accuracy:  0.966\n",
      "resnet_basic_110_test\n",
      "validation idx overlap with wrong idx human:  (58,)\n",
      "validation idx overlap with wrong idx labels:  (58,)\n",
      "num errors: (606,) accuracy:  0.9394\n",
      "sba:  0.653465346535\n",
      "validation sba:  0.637931034483\n",
      "validation accuracy:  0.942\n",
      "resnext_29_8x64d_test\n",
      "validation idx overlap with wrong idx human:  (35,)\n",
      "validation idx overlap with wrong idx labels:  (35,)\n",
      "num errors: (377,) accuracy:  0.9623\n",
      "sba:  0.689655172414\n",
      "validation sba:  0.628571428571\n",
      "validation accuracy:  0.965\n",
      "shake_shake_26_2x64d_SSI_cutout16_test\n",
      "validation idx overlap with wrong idx human:  (33,)\n",
      "validation idx overlap with wrong idx labels:  (33,)\n",
      "num errors: (296,) accuracy:  0.9704\n",
      "sba:  0.689189189189\n",
      "validation sba:  0.666666666667\n",
      "validation accuracy:  0.967\n",
      "vgg_15_BN_64_test\n",
      "validation idx overlap with wrong idx human:  (56,)\n",
      "validation idx overlap with wrong idx labels:  (56,)\n",
      "num errors: (697,) accuracy:  0.9303\n",
      "sba:  0.654232424677\n",
      "validation sba:  0.625\n",
      "validation accuracy:  0.944\n",
      "wrn_28_10_test\n",
      "validation idx overlap with wrong idx human:  (45,)\n",
      "validation idx overlap with wrong idx labels:  (45,)\n",
      "num errors: (410,) accuracy:  0.959\n",
      "sba:  0.641463414634\n",
      "validation sba:  0.688888888889\n",
      "validation accuracy:  0.955\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "sbas = []\n",
    "val_sbas = []\n",
    "val_accuracies = []\n",
    "for model, value in test_dict.items():\n",
    "    print(model)\n",
    "    value['top_guess'] = np.argmax(value['probs'], axis=1)\n",
    "    value['wrong_idx_labels'] = np.where(value['top_guess'] != test_dict[model]['labels'])[0]\n",
    "    value['wrong_idx'] = np.where(value['top_guess'] != humans_correct)[0]\n",
    "    \n",
    "    value['overlap'] = np.intersect1d(validation_idx, value['wrong_idx'])\n",
    "    print('validation idx overlap with wrong idx human: ', np.shape(value['overlap']))\n",
    "    value['overlap_labels'] = np.intersect1d(validation_idx, value['wrong_idx_labels'])\n",
    "    print('validation idx overlap with wrong idx labels: ', np.shape(value['overlap']))\n",
    "\n",
    "    value['sba'] = sba(value['probs'][value['wrong_idx']], humans[value['wrong_idx']])\n",
    "    value['validation_sba'] = sba(value['probs'][value['overlap']], humans[value['overlap']])\n",
    "    value['accuracy'] = 1 - (np.shape(value['wrong_idx'])[0] / 10000)\n",
    "    value['validation_accuracy'] = 1 - (np.shape(value['overlap'])[0] / 1000)\n",
    "    print('num errors:', np.shape(value['wrong_idx']), 'accuracy: ', value['accuracy'])\n",
    "    print('sba: ', value['sba'])\n",
    "    print('validation sba: ', value['validation_sba'])\n",
    "    print('validation accuracy: ', value['validation_accuracy'])\n",
    "    accuracies.append(value['accuracy'])\n",
    "    sbas.append(value['sba'])\n",
    "    val_sbas.append(value['validation_sba'])\n",
    "    val_accuracies.append(value['validation_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(accuracies, sbas)\n",
    "plt.title('All')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('SBA')\n",
    "print(pr(accuracies, sbas))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(sbas, val_sbas)\n",
    "plt.title('Validation')\n",
    "plt.xlabel('SBA')\n",
    "plt.ylabel('Validation SBA')\n",
    "print(pr(val_accuracies, val_sbas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_post = []\n",
    "models_post = []\n",
    "sbas_post = []\n",
    "val_sbas_post = []\n",
    "val_accuracies_post = []\n",
    "for model, value in post_dict.items():\n",
    "    print(model)\n",
    "    models_post.append(model)\n",
    "    value['top_guess'] = np.argmax(value['probs'], axis=1)\n",
    "    value['wrong_idx'] = np.where(value['top_guess'] != humans_correct)[0]\n",
    "    value['overlap'] = np.intersect1d(validation_idx, value['wrong_idx'])\n",
    "    print('validation idx overlap with wrong idx: ', np.shape(value['overlap']))\n",
    "    value['sba'] = sba(value['probs'][value['wrong_idx']], humans[value['wrong_idx']])\n",
    "    value['validation_sba'] = sba(value['probs'][value['overlap']], humans[value['overlap']])\n",
    "    value['accuracy'] = 1 - (np.shape(value['wrong_idx'])[0] / 10000)\n",
    "    value['validation_accuracy'] = 1 - (np.shape(value['overlap'])[0] / 1000)\n",
    "    print('num errors:', np.shape(value['wrong_idx']), 'accuracy: ', value['accuracy'])\n",
    "    print('sba: ', value['sba'])\n",
    "    print('validation sba: ', value['validation_sba'])\n",
    "    print('validation accuracy: ', value['validation_accuracy'])\n",
    "    accuracies_post.append(value['accuracy'])\n",
    "    sbas_post.append(value['sba'])\n",
    "    val_sbas_post.append(value['validation_sba'])\n",
    "    val_accuracies_post.append(value['validation_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_new = [(' ').join(x.split('_')[:-1]) for x in models_post]\n",
    "print(models_new)\n",
    "plt.figure()\n",
    "plt.title('SBA pre- post-tuning plot: (single) validation subset')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.plot(models_new, val_sbas, marker='o', linewidth=0)\n",
    "plt.plot(models_new, val_sbas_post, 'r', marker='x', linewidth=0)\n",
    "plt.xticks(rotation=70, ha='right')\n",
    "np.mean(np.array(val_sbas_post) - np.array(val_sbas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageTestProb = []\n",
    "for key, value in test_dict.items():\n",
    "    correct = value['labels']\n",
    "    averageTestProb.append(value['probs'])\n",
    "averageTestProb = np.mean(averageTestProb, axis=0)\n",
    "print(averageTestProb.shape, np.argmax(averageTestProb, axis = 1))\n",
    "print(correct)\n",
    "correctProb = averageTestProb[np.arange(correct.shape[0]), correct]\n",
    "print(correctProb.shape)\n",
    "\n",
    "top = np.argsort(correctProb)[:2000]\n",
    "print(top.shape, top[:5], correctProb[top[5:]])\n",
    "\n",
    "human_correct = np.argmax(humans, axis = 1)\n",
    "human_correct_prob = np.max(humans, axis = 1)\n",
    "print('hcp[:3]', human_correct_prob[:3])\n",
    "print(human_correct.shape)\n",
    "agg_NN_correct = np.argmax(averageTestProb, axis = 1)\n",
    "print(agg_NN_correct.shape)\n",
    "print(np.mean(human_correct != agg_NN_correct))\n",
    "print(np.mean(correct != agg_NN_correct))\n",
    "print(np.mean(human_correct != correct))\n",
    "\n",
    "print(1 - soft_certain(humans[top]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averageEnt = []\n",
    "for key, value in test_dict.items():\n",
    "    averageEnt.append(value['entropy'])\n",
    "averageEnt = np.mean(averageEnt, axis=0)\n",
    "print(averageEnt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ent to ent\n",
    "plt.figure()\n",
    "plt.scatter(averageEnt, human_ent)\n",
    "print('av ent to ent, all', pr(averageEnt, human_ent))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(averageEnt[top], human_ent[top])\n",
    "\n",
    "print('av ent to ent, top', pr(averageEnt[top], human_ent[top]))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(correctProb, human_ent)\n",
    "print('av prob to ent, all', pr(correctProb, human_ent))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(correctProb[top], human_ent[top])\n",
    "print('av prob to ent, top', pr(correctProb[top], human_ent[top]))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(correctProb, human_correct_prob)\n",
    "print('prob to prob, all', pr(correctProb, human_correct_prob))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(correctProb[top], human_correct_prob[top])\n",
    "print('prob to prob, top',pr(correctProb[top], human_correct_prob[top]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(human_ent[top])\n",
    "plt.title('NN bottom 20% test set')\n",
    "plt.xlim([0, 2])\n",
    "plt.xlabel('Entropy post smoothing')\n",
    "plt.ylim([0, 1000])\n",
    "plt.ylabel('#')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(human_ent)\n",
    "plt.title('All test set')\n",
    "plt.xlim([0, 2])\n",
    "plt.ylabel('#')\n",
    "plt.ylim([0, 5000])\n",
    "plt.xlabel('Entropy post smoothing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
