{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'adversarial_perturbations' from '/Users/jordanm/grad/mister_ed/adversarial_perturbations.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import config\n",
    "import matplotlib.pyplot as plt \n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap\n",
    "import adversarial_attacks_refactor as aar \n",
    "import spatial_transformers as st \n",
    "reload(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Goal here is to make sure adversarial training works under the refactored model. It _should_, but it might need \n",
    "    a few tweaks \n",
    "\"\"\"\n",
    "\n",
    "# Load up dataLoader, classifier, normer \n",
    "use_gpu = torch.cuda.is_available()\n",
    "classifier_net = cifar_loader.load_pretrained_cifar_resnet(flavor=32,\n",
    "                                                           use_gpu=use_gpu)\n",
    "classifier_net.eval()\n",
    "train_loader = cifar_loader.load_cifar_data('train', normalize=False, \n",
    "                                            batch_size=16, use_gpu=use_gpu)\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False, \n",
    "                                          batch_size=4, use_gpu=use_gpu)\n",
    "\n",
    "cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                             std=config.CIFAR10_STDS)\n",
    "\n",
    "examples, labels = next(iter(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adversarial_training.AdversarialAttackParameters object at 0x1167a4a10>\n"
     ]
    }
   ],
   "source": [
    "# Make a threat model and attack object \n",
    "reload(advtrain)\n",
    "reload(aar)\n",
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              ap.PerturbationParameters(lp_style='inf',\n",
    "                                                        lp_bound=8.0 / 255.0))\n",
    "loss_fxn = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer) # USE A PLF LOSS FXN \n",
    "fgsm_attack = aar.FGSM(classifier_net, cifar_normer, delta_threat, loss_fxn)\n",
    "attack_params = advtrain.AdversarialAttackParameters(fgsm_attack, 0.5, \n",
    "                                                     attack_specific_params={'attack_kwargs': {'step_size': 0.1}})\n",
    "print attack_params\n",
    "\n",
    "rot_threat = ap.ThreatModel(ap.ParameterizedXformAdv, \n",
    "                            ap.PerturbationParameters(lp_style='inf', \n",
    "                                                      lp_bound=10.0 / 360,\n",
    "                                                      xform_class=st.RotationTransform))\n",
    "loss_fxn_rot = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer) # USE A PLF LOSS FXN \n",
    "rot_attack = aar.PGD(classifier_net, cifar_normer, rot_threat, loss_fxn_rot)\n",
    "rot_attack_params = advtrain.AdversarialAttackParameters(rot_attack, 1.0, \n",
    "                                                     attack_specific_params={'attack_kwargs': {'step_size': 0.01}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print isinstance(attack_params, advtrain.AdversarialAttackParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Post FGSM):  0.0 correct\n",
      "[1,     1] accuracy: (0.000, 100.000)\n",
      "[1,     1] loss: 0.001391\n",
      "(Post FGSM):  0.0 correct\n",
      "[1,     2] accuracy: (0.000, 100.000)\n",
      "[1,     2] loss: 0.002157\n",
      "(Post FGSM):  37.5 correct\n",
      "[1,     3] accuracy: (37.500, 100.000)\n",
      "[1,     3] loss: 0.001262\n",
      "(Post FGSM):  25.0 correct\n",
      "[1,     4] accuracy: (25.000, 100.000)\n",
      "[1,     4] loss: 0.001397\n",
      "(Post FGSM):  12.5 correct\n",
      "[1,     5] accuracy: (12.500, 100.000)\n",
      "[1,     5] loss: 0.001979\n",
      "(Post FGSM):  37.5 correct\n",
      "[1,     6] accuracy: (37.500, 100.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-7:\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Library/Python/2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    r = index_queue.get()\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Python/2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "  File \"/Library/Python/2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    racquire()\n",
      "  File \"/Library/Python/2.7/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "KeyboardInterrupt\n",
      "    r = index_queue.get()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    racquire()\n",
      "  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "KeyboardInterrupt\n",
      "    return recv()\n",
      "    racquire()\n",
      "  File \"/Library/Python/2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9a3ee6df2f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# USE A PREBUILT TRAIN LOSS FXN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_obj.train(train_loader, 2, train_loss, attack_parameters=[attack_params], verbosity=\"snoop\", \n\u001b[0;32m----> 7\u001b[0;31m                 adversarial_save_dir='foobar', regularize_adv_scale=1.0)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordanm/grad/mister_ed/adversarial_training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, num_epochs, train_loss, optimizer, attack_parameters, use_gpu, verbosity, starting_epoch, adversarial_save_dir, regularize_adv_scale)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# backward step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(advtrain)\n",
    "            \n",
    "classifier_net.train()\n",
    "train_obj = advtrain.AdversarialTraining(classifier_net, cifar_normer, 'refactor_test', 'resnet32')\n",
    "train_loss = nn.CrossEntropyLoss() # USE A PREBUILT TRAIN LOSS FXN \n",
    "train_obj.train(train_loader, 2, train_loss, attack_parameters=[attack_params], verbosity=\"snoop\", \n",
    "                adversarial_save_dir='foobar', regularize_adv_scale=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
