{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self contained memout assertion \n",
    "\n",
    "##########################################################################\n",
    "#   IMPORT BLOCK                                                         #\n",
    "##########################################################################\n",
    "import gc \n",
    "import os\n",
    "import sys \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import checkpoints\n",
    "import subprocess\n",
    "import time \n",
    "\n",
    "# fxn taken from https://discuss.pytorch.org/t/memory-leaks-in-trans-conv/12492\n",
    "def get_gpu_memory_map():   \n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    try:\n",
    "        return float(result)\n",
    "    except:\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PETER BLACK EXAMPLE\n",
    "\n",
    "class LossObj(object):\n",
    "    def __init__(self):\n",
    "        self.nets = [] \n",
    "        \n",
    "class PartialLoss(LossObj):\n",
    "    def __init__(self, classifier):\n",
    "        super(PartialLoss, self).__init__()\n",
    "        self.classifier = classifier \n",
    "        self.nets.append(self.classifier)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        return self.classifier.forward(inp)\n",
    "        \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 10000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"BASE STATE\", get_gpu_memory_map()\n",
    "x = Variable(torch.randn(1, 1000)).cuda()\n",
    "model = MyModel().cuda()\n",
    "\n",
    "part_loss = PartialLoss(model)\n",
    "out = torch.sum(part_loss.forward(x))\n",
    "\n",
    "out.backward()\n",
    "print \"PEAK STATE\", get_gpu_memory_map()\n",
    "del model \n",
    "del part_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "time.sleep(2)\n",
    "\n",
    "print \"OUT STATE\", get_gpu_memory_map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gpu_memory_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "BATCH NUMBER: 0\n",
      "GPU MEMORY: 431.0\n",
      "GPU MEMORY: 431.0\n",
      "BATCH NUMBER: 1\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 2\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 3\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 4\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 5\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 6\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 7\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 8\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 9\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 10\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 11\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 12\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 13\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 14\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 15\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 16\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 17\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 18\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 19\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 20\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 21\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 22\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 23\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 24\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 25\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 26\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 27\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 28\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 29\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 30\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 31\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 32\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 33\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 34\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 35\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 36\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 37\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 38\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 39\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 40\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 41\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 42\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 43\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 44\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 45\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 46\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 47\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 48\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 49\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 50\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 51\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 52\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 53\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 54\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 55\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 56\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 57\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 58\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 59\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 60\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 61\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 62\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 63\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 64\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 65\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 66\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 67\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 68\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 69\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 70\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 71\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 72\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 73\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 74\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 75\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 76\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 77\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 78\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 79\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 80\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 81\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 82\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 83\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 84\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 85\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 86\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 87\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 88\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 89\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 90\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 91\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 92\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 93\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 94\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 95\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 96\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 97\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 98\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 99\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 100\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 101\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 102\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 103\n",
      "GPU MEMORY: 649.0\n",
      "GPU MEMORY: 583.0\n",
      "BATCH NUMBER: 104\n",
      "GPU MEMORY: 649.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##########################################################################\n",
    "#   FUNCTION BLOCK                                                       #\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "\n",
    "def memout_example():    \n",
    "    assert vars() == {}\n",
    "    # empty slate \n",
    "\n",
    "    # build persistent data \n",
    "    val_loader = cifar_loader.load_cifar_data('val', normalize=False, batch_size=16, use_gpu=True)\n",
    "    \n",
    "    base_model = cifar_resnets.resnet32()\n",
    "    adv_trained_net = checkpoints.load_state_dict_from_filename('half_trained_madry.th', base_model)\n",
    "    adv_trained_net.cuda()\n",
    "    cifar_normer = utils.DifferentiableNormalize(mean=config.CIFAR10_MEANS,\n",
    "                                           std=config.CIFAR10_STDS)        \n",
    "    perceptual_loss = plf.PerceptualXentropy(adv_trained_net, normalizer=cifar_normer, use_gpu=True)            \n",
    "    pgd_attack_obj = aa.LInfPGD(adv_trained_net, cifar_normer, perceptual_loss, use_gpu=True)\n",
    "        \n",
    "    # now loop through batches and show that there's something hanging somewhere...\n",
    "    for batch_no, (batch, labels) in enumerate(val_loader):\n",
    "        \n",
    "        # clean up garbage and clear cuda cache as much as possible \n",
    "        gc.collect()\n",
    "        print \"BATCH NUMBER: %s\" % batch_no\n",
    "        print \"GPU MEMORY: %s\" % get_gpu_memory_map()\n",
    "        # assert sorted(vars().keys()) == sorted(['labels', 'val_loader', 'batch', 'batch_no'])\n",
    "        torch.cuda.empty_cache()\n",
    "        time.sleep(2)\n",
    "        print \"GPU MEMORY: %s\" % get_gpu_memory_map()\n",
    "\n",
    "\n",
    "        \n",
    "        # load things needed for attack \n",
    "\n",
    "        \n",
    "        adv_images = pgd_attack_obj.attack(batch.cuda(), labels.cuda(), l_inf_bound =8.0/255.0, num_iterations=10, \n",
    "                                           verbose=False)\n",
    "        \n",
    "        # push things to cpu (in hopes it gets them out of the cache)\n",
    "        # also delete everything and be sure to collect garbage before next batch \n",
    "        batch.cpu()\n",
    "        labels.cpu()\n",
    "        del adv_images\n",
    "        del batch \n",
    "        del labels \n",
    "        # del pgd_attack_obj \n",
    "        # del pgd_perceptual_loss\n",
    "        # del cifar_normer\n",
    "        # adv_trained_net.cpu()\n",
    "        # del adv_trained_net \n",
    "        # del base_model \n",
    "        \n",
    "        \n",
    "    return\n",
    "    \n",
    "    \n",
    "##########################################################################\n",
    "#   BREAK THE PLANET BLOCK                                               #\n",
    "##########################################################################\n",
    "print memout_example()\n",
    "print \"SOMEHOW THIS WORKED??\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def memout_example_loss_direct():    \n",
    "    assert vars() == {}\n",
    "    # empty slate \n",
    "\n",
    "    # build persistent \n",
    "    data \n",
    "    val_loader = cifar_loader.load_cifar_data('val', normalize=False, batch_size=16, use_gpu=True)\n",
    "    \n",
    "    lpips = lf.LpipsRegularization(None, use_gpu=True) # need to setup attack batch \n",
    "    for batch_no, (batch, labels) in enumerate(val_loader):\n",
    "        gc.collect()\n",
    "        print \"BATCH NUMBER: %s\" % batch_no\n",
    "        # assert sorted(vars().keys()) == sorted(['labels', 'val_loader', 'batch', 'batch_no'])\n",
    "        torch.cuda.empty_cache()\n",
    "        time.sleep(2)\n",
    "        print \"GPU MEMORY: %s\" % get_gpu_memory_map()        \n",
    "        batch = Variable(batch.cuda(), requires_grad=True)\n",
    "        lpips.setup_attack_batch(batch)\n",
    "        output = torch.sum(lpips.forward(batch))\n",
    "        output.backward()\n",
    "\n",
    "foo = memout_example_loss_direct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
