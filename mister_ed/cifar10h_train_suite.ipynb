{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os, sys, re\n",
    "# module_path = os.path.abspath(os.path.join('..'))\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)\n",
    "\n",
    "import config\n",
    "import matplotlib.pyplot as plt \n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_attacks as aa\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap\n",
    "import adversarial_attacks_refactor as aar \n",
    "import spatial_transformers as st \n",
    "import importlib\n",
    "importlib.reload(ap)\n",
    "\n",
    "### START pytorch_image_classification imports\n",
    "import time, random, json, logging, argparse, csv\n",
    "# import numpy as np\n",
    "# import torch.optim\n",
    "# import torch.utils.data\n",
    "# import torch.backends.cudnn\n",
    "# import torchvision.utils\n",
    "from pytorch_image_classification_dataloader_c10h import get_loader\n",
    "from pytorch_image_classification_utils import (str2bool, load_model, save_checkpoint, create_optimizer,\n",
    "                                                AverageMeter, mixup, CrossEntropyLoss, onehot)\n",
    "# from rutils_run import save_checkpoint_epoch\n",
    "from pytorch_image_classification_argparser import get_config\n",
    "\n",
    "use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'tmp_reference_model/model_best_state_resnet_basic_110_con_False_lr_001_seed_0.pth'\n",
      "=> loaded checkpoint 'tmp_reference_model/model_best_state_resnet_basic_110_con_False_lr_001_seed_0.pth' (epoch 72)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = ['']\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--arch', type=str, default='resnet')\n",
    "    parser.add_argument('--config', type=str, default='tmp_reference_model/resnet_basic_110_config.json')\n",
    "    # model config (VGG)\n",
    "    parser.add_argument('--n_channels', type=str)\n",
    "    parser.add_argument('--n_layers', type=str)\n",
    "    parser.add_argument('--use_bn', type=str2bool)\n",
    "    #\n",
    "    parser.add_argument('--base_channels', type=int)\n",
    "    parser.add_argument('--block_type', type=str)\n",
    "    parser.add_argument('--depth', type=int)\n",
    "    # model config (ResNet-preact)\n",
    "    parser.add_argument('--remove_first_relu', type=str2bool)\n",
    "    parser.add_argument('--add_last_bn', type=str2bool)\n",
    "    parser.add_argument('--preact_stage', type=str)\n",
    "    # model config (WRN)\n",
    "    parser.add_argument('--widening_factor', type=int)\n",
    "    # model config (DenseNet)\n",
    "    parser.add_argument('--growth_rate', type=int)\n",
    "    parser.add_argument('--compression_rate', type=float)\n",
    "    # model config (WRN, DenseNet)\n",
    "    parser.add_argument('--drop_rate', type=float)\n",
    "    # model config (PyramidNet)\n",
    "    parser.add_argument('--pyramid_alpha', type=int)\n",
    "    # model config (ResNeXt)\n",
    "    parser.add_argument('--cardinality', type=int)\n",
    "    # model config (shake-shake)\n",
    "    parser.add_argument('--shake_forward', type=str2bool)\n",
    "    parser.add_argument('--shake_backward', type=str2bool)\n",
    "    parser.add_argument('--shake_image', type=str2bool)\n",
    "    # model config (SENet)\n",
    "    parser.add_argument('--se_reduction', type=int)\n",
    "\n",
    "    parser.add_argument('--outdir', type=str, required=False)\n",
    "    parser.add_argument('--seed', type=int, default=17)\n",
    "    parser.add_argument('--test_first', type=str2bool, default=True)\n",
    "    parser.add_argument('--gpu', type=str, default='0') # -1 for CPU\n",
    "    # TensorBoard configuration\n",
    "    parser.add_argument(\n",
    "        '--tensorboard', dest='tensorboard', action='store_true', default=True)\n",
    "    parser.add_argument(\n",
    "        '--no-tensorboard', dest='tensorboard', action='store_false')\n",
    "    parser.add_argument('--tensorboard_train_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_test_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_model_params', action='store_true')\n",
    "    # configuration of optimizer\n",
    "    parser.add_argument('--epochs', type=int)\n",
    "    parser.add_argument('--batch_size', type=int)\n",
    "    parser.add_argument('--optimizer', type=str, choices=['sgd', 'adam'])\n",
    "    parser.add_argument('--base_lr', type=float)\n",
    "    parser.add_argument('--weight_decay', type=float)\n",
    "    # configuration for SGD\n",
    "    parser.add_argument('--momentum', type=float)\n",
    "    parser.add_argument('--nesterov', type=str2bool)\n",
    "    # configuration for learning rate scheduler\n",
    "    parser.add_argument(\n",
    "        '--scheduler', type=str, choices=['none', 'multistep', 'cosine'])\n",
    "    # configuration for multi-step scheduler]\n",
    "    parser.add_argument('--milestones', type=str)\n",
    "    parser.add_argument('--lr_decay', type=float)\n",
    "    # configuration for cosine-annealing scheduler]\n",
    "    parser.add_argument('--lr_min', type=float, default=0)\n",
    "    # configuration for Adam\n",
    "    parser.add_argument('--betas', type=str)\n",
    "    # configuration of data loader\n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default='CIFAR10',\n",
    "        choices=['CIFAR10', 'CIFAR10H'])\n",
    "    parser.add_argument('--num_workers', type=int, default=7)\n",
    "    # cutout configuration\n",
    "    parser.add_argument('--use_cutout', action='store_true', default=False)\n",
    "    parser.add_argument('--cutout_size', type=int, default=16)\n",
    "    parser.add_argument('--cutout_prob', type=float, default=1)\n",
    "    parser.add_argument('--cutout_inside', action='store_true', default=False)\n",
    "    # random erasing configuration\n",
    "    parser.add_argument(\n",
    "        '--use_random_erasing', action='store_true', default=False)\n",
    "    parser.add_argument('--random_erasing_prob', type=float, default=0.5)\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_area_ratio_range', type=str, default='[0.02, 0.4]')\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_min_aspect_ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--random_erasing_max_attempt', type=int, default=20)\n",
    "    # mixup configuration\n",
    "    parser.add_argument('--use_mixup', action='store_true', default=False)\n",
    "    parser.add_argument('--mixup_alpha', type=float, default=1)\n",
    "\n",
    "    # previous model weights to load if any\n",
    "    parser.add_argument('--resume', type=str)\n",
    "    # whether to tune to human labels\n",
    "    parser.add_argument('--human_tune', action='store_true', default=False)\n",
    "    # where to save the loss/accuracy for c10h to a csv file\n",
    "    parser.add_argument('--c10h_scores_outdir', type=str, default='tmp')\n",
    "    # c10h scores save interval (in epochs)\n",
    "    parser.add_argument('--c10h_save_interval', type=str, default='1') # changed from int\n",
    "    # how much of the data to use use for test for c10h training\n",
    "    parser.add_argument('--c10h_testsplit_percent', type=float, default=0.1)\n",
    "    # seed for splitting the c10h data into train/test\n",
    "    parser.add_argument('--c10h_datasplit_seed', type=int, default=999)\n",
    "    # whether to use the cifar10 labels for the human test set (CONTROL)\n",
    "    parser.add_argument('--nonhuman_control', type=str2bool, default=False)\n",
    "    # whether to sample from the human labels to get one-hot samples\n",
    "    parser.add_argument('--c10h_sample', action='store_true', default=False)\n",
    "    # whether to save to out_dir\n",
    "    parser.add_argument('--no_output', action='store_true', default=False)\n",
    "    # to test the loaded model and don't train\n",
    "    parser.add_argument('--test_only', action='store_true', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # if not is_tensorboard_available:\n",
    "    args.tensorboard = False\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return config\n",
    "\n",
    "config = parse_args()\n",
    "\n",
    "run_config = config['run_config']\n",
    "\n",
    "run_config['resume'] = 'tmp_reference_model/model_best_state_resnet_basic_110_con_False_lr_001_seed_0.pth'\n",
    "#run_config['resume'] = 'tmp_reference_model/model_best_state.pth'\n",
    "\n",
    "def load_our_model(config, weights_path):\n",
    "        \n",
    "    our_model = load_model(config['model_config'])\n",
    "    \n",
    "    # load pretrained weights if given\n",
    "    if os.path.isfile(weights_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(weights_path))\n",
    "\n",
    "        # Resolve CPU/GPU stuff\n",
    "        if use_gpu:\n",
    "            map_location = None\n",
    "        else:\n",
    "            map_location= (lambda s, l: s)\n",
    "\n",
    "        checkpoint = torch.load(weights_path,\n",
    "                                map_location=map_location)\n",
    "\n",
    "        correct_state_dict = {re.sub(r'^module\\.', '', k): v for k, v in\n",
    "                              checkpoint['state_dict'].items()}\n",
    "\n",
    "        our_model.load_state_dict(correct_state_dict)\n",
    "\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(weights_path, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(weights_path))\n",
    "        \n",
    "    return our_model\n",
    "\n",
    "model = load_our_model(config, run_config['resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'tmp_reference_model/model_best_state_resnet_basic_110_con_False_lr_001_seed_0.pth'\n",
      "=> loaded checkpoint 'tmp_reference_model/model_best_state_resnet_basic_110_con_False_lr_001_seed_0.pth' (epoch 72)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Goal here is to make sure adversarial training works under the refactored model. It _should_, but it might need \n",
    "    a few tweaks \n",
    "\"\"\"\n",
    "\n",
    "# Load up dataLoader, classifier, normer \n",
    "# use_gpu = torch.cuda.is_available()\n",
    "# classifier_net = cifar_loader.load_pretrained_cifar_resnet(flavor=32,\n",
    "#                                                            use_gpu=use_gpu)\n",
    "\n",
    "classifier_net = load_our_model(config, run_config['resume'])\n",
    "\n",
    "classifier_net.eval()\n",
    "train_loader = cifar_loader.load_cifar_data('train', normalize=False, \n",
    "                                            batch_size=16, use_gpu=use_gpu)\n",
    "val_loader = cifar_loader.load_cifar_data('val', normalize=False, \n",
    "                                          batch_size=4, use_gpu=use_gpu)\n",
    "\n",
    "cifar_normer = utils.DifferentiableNormalize(mean=np.array([0.4914, 0.4822, 0.4465]),\n",
    "                                             std=np.array([0.2470, 0.2435, 0.2616]))\n",
    "\n",
    "examples, labels = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<adversarial_training.AdversarialAttackParameters object at 0x7ff8cdbbeb00>\n"
     ]
    }
   ],
   "source": [
    "# Make a threat model and attack object \n",
    "importlib.reload(advtrain)\n",
    "importlib.reload(aar)\n",
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              ap.PerturbationParameters(lp_style='inf',\n",
    "                                                        lp_bound=8.0 / 255.0))\n",
    "loss_fxn = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer) # USE A PLF LOSS FXN \n",
    "fgsm_attack = aar.FGSM(classifier_net, cifar_normer, delta_threat, loss_fxn)\n",
    "attack_params = advtrain.AdversarialAttackParameters(fgsm_attack, 0.5, \n",
    "                                                     attack_specific_params={'attack_kwargs': {'step_size': 0.1}})\n",
    "print(attack_params)\n",
    "\n",
    "rot_threat = ap.ThreatModel(ap.ParameterizedXformAdv, \n",
    "                            ap.PerturbationParameters(lp_style='inf', \n",
    "                                                      lp_bound=10.0 / 360,\n",
    "                                                      xform_class=st.RotationTransform))\n",
    "loss_fxn_rot = plf.VanillaXentropy(classifier_net, normalizer=cifar_normer) # USE A PLF LOSS FXN \n",
    "rot_attack = aar.PGD(classifier_net, cifar_normer, rot_threat, loss_fxn_rot)\n",
    "rot_attack_params = advtrain.AdversarialAttackParameters(rot_attack, 1.0, \n",
    "                                                     attack_specific_params={'attack_kwargs': {'step_size': 0.01}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(attack_params, advtrain.AdversarialAttackParameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Post FGSM):  25.0 correct\n",
      "[1,     1] accuracy: (25.000, 75.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7ff8cda93358>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 399, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 378, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 151, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/joshuacp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed/output_images/shake_shake/3823205652074535.examples.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e9298125a048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# USE A PREBUILT TRAIN LOSS FXN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m train_obj.train(train_loader, 2, train_loss, attack_parameters=[attack_params], verbosity=\"snoop\", \n\u001b[0;32m----> 7\u001b[0;31m                 adversarial_save_dir='shake_shake', regularize_adv_scale=1.0)\n\u001b[0m",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed/adversarial_training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, num_epochs, train_loss, optimizer, attack_parameters, use_gpu, verbosity, starting_epoch, adversarial_save_dir, regularize_adv_scale)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                                      \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                                      \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                                      adv_saver)\n\u001b[0m\u001b[1;32m    395\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0;31m# Now proceed with standard training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed/adversarial_training.py\u001b[0m in \u001b[0;36m_attack_subroutine\u001b[0;34m(self, attack_parameters, inputs, labels, epoch_num, minibatch_num, adv_saver)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madv_saver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Save the adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0madv_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0madv_inputs_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed/utils/checkpoints.py\u001b[0m in \u001b[0;36msave_minibatch\u001b[0;34m(self, examples, labels)\u001b[0m\n\u001b[1;32m    202\u001b[0m         example_path = os.path.join(OUTPUT_IMAGE_DIR, self.image_subdirectory,\n\u001b[1;32m    203\u001b[0m                                     example_file)\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mlabel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s.labels.npy'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrandom_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed/output_images/shake_shake/3823205652074535.examples.npy'"
     ]
    }
   ],
   "source": [
    "importlib.reload(advtrain)\n",
    "            \n",
    "classifier_net.train()\n",
    "train_obj = advtrain.AdversarialTraining(classifier_net, cifar_normer, 'refactor_test', 'shake_shake')\n",
    "train_loss = nn.CrossEntropyLoss() # USE A PREBUILT TRAIN LOSS FXN \n",
    "train_obj.train(train_loader, 2, train_loss, attack_parameters=[attack_params], verbosity=\"snoop\", \n",
    "                adversarial_save_dir='shake_shake', regularize_adv_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
