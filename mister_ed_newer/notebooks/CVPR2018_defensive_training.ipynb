{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training with `mister_ed`\n",
    "This file will contain the basics on how to perform adversarial training under the `mister_ed` framework. It's highly recommended that you have walked through tutorial_1 before going through this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we'll start by importing everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuacp/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/joshuacp/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/joshuacp/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "use_gpu = False\n",
    "\n",
    "# EXTERNAL LIBRARY IMPORTS\n",
    "import numpy as np \n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch # Need torch version >=0.3\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "assert float(torch.__version__[:3]) >= 0.3\n",
    "\n",
    "# MISTER ED SPECIFIC IMPORT BLOCK\n",
    "# (here we do things so relative imports work )\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os, sys, re, gc, pickle \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap \n",
    "import adversarial_attacks as aa\n",
    "import spatial_transformers as st\n",
    "\n",
    "### START pytorch_image_classification imports\n",
    "import time, random, json, logging, argparse, csv\n",
    "from pytorch_image_classification_dataloader_c10h import get_loader\n",
    "from pytorch_image_classification_utils import (str2bool, load_model, save_checkpoint, create_optimizer,\n",
    "                                                AverageMeter, mixup, CrossEntropyLoss, onehot)\n",
    "# from rutils_run import save_checkpoint_epoch\n",
    "from pytorch_image_classification_argparser import get_config\n",
    "\n",
    "sys.argv = ['']\n",
    "\n",
    "def parse_args(arch, mdl_config):\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--arch', type=str, default='resnet')\n",
    "    parser.add_argument('--arch', type=str, default=arch)\n",
    "    # parser.add_argument('--config', type=str, default='tmp_reference_model/resnet_basic_110_config.json')\n",
    "    parser.add_argument('--config', type=str, default=mdl_config)\n",
    "    # model config (VGG)\n",
    "    parser.add_argument('--n_channels', type=str)\n",
    "    parser.add_argument('--n_layers', type=str)\n",
    "    parser.add_argument('--use_bn', type=str2bool)\n",
    "    #\n",
    "    parser.add_argument('--base_channels', type=int)\n",
    "    parser.add_argument('--block_type', type=str)\n",
    "    parser.add_argument('--depth', type=int)\n",
    "    # model config (ResNet-preact)\n",
    "    parser.add_argument('--remove_first_relu', type=str2bool)\n",
    "    parser.add_argument('--add_last_bn', type=str2bool)\n",
    "    parser.add_argument('--preact_stage', type=str)\n",
    "    # model config (WRN)\n",
    "    parser.add_argument('--widening_factor', type=int)\n",
    "    # model config (DenseNet)\n",
    "    parser.add_argument('--growth_rate', type=int)\n",
    "    parser.add_argument('--compression_rate', type=float)\n",
    "    # model config (WRN, DenseNet)\n",
    "    parser.add_argument('--drop_rate', type=float)\n",
    "    # model config (PyramidNet)\n",
    "    parser.add_argument('--pyramid_alpha', type=int)\n",
    "    # model config (ResNeXt)\n",
    "    parser.add_argument('--cardinality', type=int)\n",
    "    # model config (shake-shake)\n",
    "    parser.add_argument('--shake_forward', type=str2bool)\n",
    "    parser.add_argument('--shake_backward', type=str2bool)\n",
    "    parser.add_argument('--shake_image', type=str2bool)\n",
    "    # model config (SENet)\n",
    "    parser.add_argument('--se_reduction', type=int)\n",
    "\n",
    "    parser.add_argument('--outdir', type=str, required=False)\n",
    "    parser.add_argument('--seed', type=int, default=17)\n",
    "    parser.add_argument('--test_first', type=str2bool, default=True)\n",
    "    parser.add_argument('--gpu', type=str, default='0') # -1 for CPU\n",
    "    # TensorBoard configuration\n",
    "    parser.add_argument(\n",
    "        '--tensorboard', dest='tensorboard', action='store_true', default=True)\n",
    "    parser.add_argument(\n",
    "        '--no-tensorboard', dest='tensorboard', action='store_false')\n",
    "    parser.add_argument('--tensorboard_train_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_test_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_model_params', action='store_true')\n",
    "    # configuration of optimizer\n",
    "    parser.add_argument('--epochs', type=int)\n",
    "    parser.add_argument('--batch_size', type=int, default=500)\n",
    "    parser.add_argument('--optimizer', type=str, choices=['sgd', 'adam'])\n",
    "    parser.add_argument('--base_lr', type=float)\n",
    "    parser.add_argument('--weight_decay', type=float)\n",
    "    # configuration for SGD\n",
    "    parser.add_argument('--momentum', type=float)\n",
    "    parser.add_argument('--nesterov', type=str2bool)\n",
    "    # configuration for learning rate scheduler\n",
    "    parser.add_argument(\n",
    "        '--scheduler', type=str, choices=['none', 'multistep', 'cosine'])\n",
    "    # configuration for multi-step scheduler]\n",
    "    parser.add_argument('--milestones', type=str)\n",
    "    parser.add_argument('--lr_decay', type=float)\n",
    "    # configuration for cosine-annealing scheduler]\n",
    "    parser.add_argument('--lr_min', type=float, default=0)\n",
    "    # configuration for Adam\n",
    "    parser.add_argument('--betas', type=str)\n",
    "    # configuration of data loader\n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default='CIFAR10H',\n",
    "        choices=['CIFAR10', 'CIFAR10H'])\n",
    "    parser.add_argument('--num_workers', type=int, default=7)\n",
    "    # cutout configuration\n",
    "    parser.add_argument('--use_cutout', action='store_true', default=False)\n",
    "    parser.add_argument('--cutout_size', type=int, default=16)\n",
    "    parser.add_argument('--cutout_prob', type=float, default=1)\n",
    "    parser.add_argument('--cutout_inside', action='store_true', default=False)\n",
    "    # random erasing configuration\n",
    "    parser.add_argument(\n",
    "        '--use_random_erasing', action='store_true', default=False)\n",
    "    parser.add_argument('--random_erasing_prob', type=float, default=0.5)\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_area_ratio_range', type=str, default='[0.02, 0.4]')\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_min_aspect_ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--random_erasing_max_attempt', type=int, default=20)\n",
    "    # mixup configuration\n",
    "    parser.add_argument('--use_mixup', action='store_true', default=False)\n",
    "    parser.add_argument('--mixup_alpha', type=float, default=1)\n",
    "\n",
    "    # previous model weights to load if any\n",
    "    parser.add_argument('--resume', type=str)\n",
    "    # whether to tune to human labels\n",
    "    parser.add_argument('--human_tune', action='store_true', default=False)\n",
    "    # where to save the loss/accuracy for c10h to a csv file\n",
    "    parser.add_argument('--c10h_scores_outdir', type=str, default='tmp')\n",
    "    # c10h scores save interval (in epochs)\n",
    "    parser.add_argument('--c10h_save_interval', type=str, default='1') # changed from int\n",
    "    # how much of the data to use use for test for c10h training\n",
    "    parser.add_argument('--c10h_testsplit_percent', type=float, default=0.1)\n",
    "    # seed for splitting the c10h data into train/test\n",
    "    parser.add_argument('--c10h_datasplit_seed', type=int, default=999)\n",
    "    # whether to use the cifar10 labels for the human test set (CONTROL)\n",
    "    parser.add_argument('--nonhuman_control', type=str2bool, default=False)\n",
    "    # whether to sample from the human labels to get one-hot samples\n",
    "    parser.add_argument('--c10h_sample', action='store_true', default=False)\n",
    "    # whether to save to out_dir\n",
    "    parser.add_argument('--no_output', action='store_true', default=False)\n",
    "    # to test the loaded model and don't train\n",
    "    parser.add_argument('--test_only', action='store_true', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # if not is_tensorboard_available:\n",
    "    args.tensorboard = False\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_our_model(config, weights_path):\n",
    "        \n",
    "    our_model = load_model(config['model_config'])\n",
    "    \n",
    "    # load pretrained weights if given\n",
    "    if os.path.isfile(weights_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(weights_path))\n",
    "\n",
    "        # Resolve CPU/GPU stuff\n",
    "        if use_gpu:\n",
    "            map_location = None\n",
    "        else:\n",
    "            map_location= (lambda s, l: s)\n",
    "\n",
    "        checkpoint = torch.load(weights_path,\n",
    "                                map_location=map_location)\n",
    "\n",
    "        correct_state_dict = {re.sub(r'^module\\.', '', k): v for k, v in\n",
    "                              checkpoint['state_dict'].items()}\n",
    "\n",
    "        our_model.load_state_dict(correct_state_dict)\n",
    "\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(weights_path, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(weights_path))\n",
    "        \n",
    "    return our_model\n",
    "\n",
    "_, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20,\n",
    "                                                          return_normalizer=True)\n",
    "del _\n",
    "\n",
    "root = '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/'\n",
    "\n",
    "def get_arch(name):\n",
    "    if 'vgg_15_BN_64' in name: return 'vgg'\n",
    "    if 'resnet_basic_110' in name: return 'resnet' \n",
    "    if 'resnet_preact_bottleneck_164' in name: return 'resnet_preact' \n",
    "    if 'wrn_28_10' in name: return 'wrn' \n",
    "    if 'densenet_BC_100_12' in name: return 'densenet' \n",
    "    if 'pyramidnet_basic_110_270' in name: return 'pyramidnet' \n",
    "    if 'resnext_29_8x64d' in name: return 'resnext' \n",
    "    if 'shake_shake_26_2x64d_SSI_cutout16' in name: return 'shake_shake'\n",
    "    return 'NOT FOUND!!!'\n",
    "\n",
    "def get_meta(verbose=False, filt=None):\n",
    "    model_meta = []\n",
    "    for folder in os.listdir(root):\n",
    "        if filt:\n",
    "            if filt not in folder:\n",
    "                continue\n",
    "        param_folders = os.listdir(os.path.join(root, folder))\n",
    "        for param_folder in param_folders:\n",
    "            pth_file = os.listdir(os.path.join(root, folder, param_folder))[0]\n",
    "            meta = {}\n",
    "            meta['arch'] = get_arch(folder)\n",
    "            meta['model_name'] = folder\n",
    "            meta['param_folder'] = param_folder\n",
    "            meta['pth_file'] = pth_file\n",
    "            if 'con_True' in param_folder:\n",
    "                meta['human'] = False\n",
    "            else:\n",
    "                meta['human'] = True  \n",
    "\n",
    "            model_meta.append(meta)\n",
    "            if verbose: print(meta)\n",
    "    return model_meta\n",
    "\n",
    "# model_meta = get_meta(verbose=True, filt='shake_shake')\n",
    "model_meta = get_meta(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shake_shake_26_2x64d_SSI_cutout16 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth' (epoch 123)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9873\n",
      "fgsm8   :  0.3964\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.025863481903076\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964], 'avg_loss_value': [4.025863481903076]}, 'ground': {'top1': [0.9873]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8827\n",
      "fgsm8   :  0.3257\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.8722071922302246\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257], 'avg_loss_value': [4.025863481903076, 1.8722071922302246]}, 'ground': {'top1': [0.9873, 0.8827]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9139\n",
      "fgsm8   :  0.4396\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.488598836517334\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9401\n",
      "fgsm8   :  0.5135\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.321458145904541\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9419\n",
      "fgsm8   :  0.5467\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2211425775527953\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9433\n",
      "fgsm8   :  0.54\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2433390412330627\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9488\n",
      "fgsm8   :  0.5699\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.1566463842391967\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54, 0.5699], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627, 1.1566463842391967]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433, 0.9488]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9515\n",
      "fgsm8   :  0.6347\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.0132914852142334\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54, 0.5699, 0.6347], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627, 1.1566463842391967, 1.0132914852142334]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433, 0.9488, 0.9515]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9572\n",
      "fgsm8   :  0.6435\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.9903058694839477\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54, 0.5699, 0.6347, 0.6435], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627, 1.1566463842391967, 1.0132914852142334, 0.9903058694839477]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433, 0.9488, 0.9515, 0.9572]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9662\n",
      "fgsm8   :  0.6696\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.9179153882980347\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54, 0.5699, 0.6347, 0.6435, 0.6696], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627, 1.1566463842391967, 1.0132914852142334, 0.9903058694839477, 0.9179153882980347]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433, 0.9488, 0.9515, 0.9572, 0.9662]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9665\n",
      "fgsm8   :  0.6696\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.9230493549346924\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.3964, 0.3257, 0.4396, 0.5135, 0.5467, 0.54, 0.5699, 0.6347, 0.6435, 0.6696, 0.6696], 'avg_loss_value': [4.025863481903076, 1.8722071922302246, 1.488598836517334, 1.321458145904541, 1.2211425775527953, 1.2433390412330627, 1.1566463842391967, 1.0132914852142334, 0.9903058694839477, 0.9179153882980347, 0.9230493549346924]}, 'ground': {'top1': [0.9873, 0.8827, 0.9139, 0.9401, 0.9419, 0.9433, 0.9488, 0.9515, 0.9572, 0.9662, 0.9665]}}\n",
      "shake_shake_26_2x64d_SSI_cutout16 True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 69)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9865\n",
      "fgsm8   :  0.3894\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.0862973037719725\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894], 'avg_loss_value': [2.0862973037719725]}, 'ground': {'top1': [0.9865]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8974\n",
      "fgsm8   :  0.3879\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6194122533798219\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219]}, 'ground': {'top1': [0.9865, 0.8974]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9372\n",
      "fgsm8   :  0.4393\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.460618438911438\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9216\n",
      "fgsm8   :  0.4818\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3526458272933959\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9463\n",
      "fgsm8   :  0.5464\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.23408611869812\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9482\n",
      "fgsm8   :  0.5298\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2431520824432374\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9441\n",
      "fgsm8   :  0.5603\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2331078217506408\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298, 0.5603], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374, 1.2331078217506408]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482, 0.9441]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9573\n",
      "fgsm8   :  0.6193\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.0434134084701538\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298, 0.5603, 0.6193], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374, 1.2331078217506408, 1.0434134084701538]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482, 0.9441, 0.9573]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9575\n",
      "fgsm8   :  0.6257\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.0509875589370727\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298, 0.5603, 0.6193, 0.6257], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374, 1.2331078217506408, 1.0434134084701538, 1.0509875589370727]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482, 0.9441, 0.9573, 0.9575]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9706\n",
      "fgsm8   :  0.664\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.9189196901321411\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298, 0.5603, 0.6193, 0.6257, 0.664], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374, 1.2331078217506408, 1.0434134084701538, 1.0509875589370727, 0.9189196901321411]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482, 0.9441, 0.9573, 0.9575, 0.9706]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9688\n",
      "fgsm8   :  0.689\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.8711016188621521\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.3894, 0.3879, 0.4393, 0.4818, 0.5464, 0.5298, 0.5603, 0.6193, 0.6257, 0.664, 0.689], 'avg_loss_value': [2.0862973037719725, 1.6194122533798219, 1.460618438911438, 1.3526458272933959, 1.23408611869812, 1.2431520824432374, 1.2331078217506408, 1.0434134084701538, 1.0509875589370727, 0.9189196901321411, 0.8711016188621521]}, 'ground': {'top1': [0.9865, 0.8974, 0.9372, 0.9216, 0.9463, 0.9482, 0.9441, 0.9573, 0.9575, 0.9706, 0.9688]}}\n",
      "resnet_preact_bottleneck_164 False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_True_lr_0.001_seed_2/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_True_lr_0.001_seed_2/model_best_state_c10h_val_c10_loss.pth' (epoch 33)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9786\n",
      "fgsm8   :  0.1696\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.253935385894775\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696], 'avg_loss_value': [6.253935385894775]}, 'ground': {'top1': [0.9786]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9224\n",
      "fgsm8   :  0.3268\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.741065620803833\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268], 'avg_loss_value': [6.253935385894775, 1.741065620803833]}, 'ground': {'top1': [0.9786, 0.9224]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9336\n",
      "fgsm8   :  0.3886\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.595640894317627\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9461\n",
      "fgsm8   :  0.4475\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.466677943611145\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9354\n",
      "fgsm8   :  0.4484\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4693093456268311\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.946\n",
      "fgsm8   :  0.4585\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.442729370689392\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9576\n",
      "fgsm8   :  0.4962\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.343946573638916\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585, 0.4962], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392, 1.343946573638916]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946, 0.9576]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9588\n",
      "fgsm8   :  0.4867\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3657300287246703\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585, 0.4962, 0.4867], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392, 1.343946573638916, 1.3657300287246703]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946, 0.9576, 0.9588]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9586\n",
      "fgsm8   :  0.5368\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2519854515075683\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585, 0.4962, 0.4867, 0.5368], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392, 1.343946573638916, 1.3657300287246703, 1.2519854515075683]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946, 0.9576, 0.9588, 0.9586]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.965\n",
      "fgsm8   :  0.5245\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2677793004989624\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585, 0.4962, 0.4867, 0.5368, 0.5245], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392, 1.343946573638916, 1.3657300287246703, 1.2519854515075683, 1.2677793004989624]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946, 0.9576, 0.9588, 0.9586, 0.965]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9697\n",
      "fgsm8   :  0.5568\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.1923402068138123\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1696, 0.3268, 0.3886, 0.4475, 0.4484, 0.4585, 0.4962, 0.4867, 0.5368, 0.5245, 0.5568], 'avg_loss_value': [6.253935385894775, 1.741065620803833, 1.595640894317627, 1.466677943611145, 1.4693093456268311, 1.442729370689392, 1.343946573638916, 1.3657300287246703, 1.2519854515075683, 1.2677793004989624, 1.1923402068138123]}, 'ground': {'top1': [0.9786, 0.9224, 0.9336, 0.9461, 0.9354, 0.946, 0.9576, 0.9588, 0.9586, 0.965, 0.9697]}}\n",
      "resnet_preact_bottleneck_164 True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_False_lr_0.1_seed_1/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_False_lr_0.1_seed_1/model_best_state_c10h_val_loss.pth' (epoch 115)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9825\n",
      "fgsm8   :  0.2944\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.5545367721557617\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944], 'avg_loss_value': [2.5545367721557617]}, 'ground': {'top1': [0.9825]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8993\n",
      "fgsm8   :  0.384\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6571683771133423\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423]}, 'ground': {'top1': [0.9825, 0.8993]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9589\n",
      "fgsm8   :  0.4289\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4962632768630981\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9528\n",
      "fgsm8   :  0.4953\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3423958326339722\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9763\n",
      "fgsm8   :  0.4797\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3948355348587036\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9553\n",
      "fgsm8   :  0.5136\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.305968056869507\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.962\n",
      "fgsm8   :  0.5185\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3116935054779053\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136, 0.5185], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507, 1.3116935054779053]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553, 0.962]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9672\n",
      "fgsm8   :  0.5803\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.1284986132621766\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136, 0.5185, 0.5803], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507, 1.3116935054779053, 1.1284986132621766]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553, 0.962, 0.9672]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9699\n",
      "fgsm8   :  0.5883\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.1599097173690796\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136, 0.5185, 0.5803, 0.5883], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507, 1.3116935054779053, 1.1284986132621766, 1.1599097173690796]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553, 0.962, 0.9672, 0.9699]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.969\n",
      "fgsm8   :  0.588\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.1051922302246093\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136, 0.5185, 0.5803, 0.5883, 0.588], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507, 1.3116935054779053, 1.1284986132621766, 1.1599097173690796, 1.1051922302246093]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553, 0.962, 0.9672, 0.9699, 0.969]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9742\n",
      "fgsm8   :  0.6237\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.0416396495819091\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2944, 0.384, 0.4289, 0.4953, 0.4797, 0.5136, 0.5185, 0.5803, 0.5883, 0.588, 0.6237], 'avg_loss_value': [2.5545367721557617, 1.6571683771133423, 1.4962632768630981, 1.3423958326339722, 1.3948355348587036, 1.305968056869507, 1.3116935054779053, 1.1284986132621766, 1.1599097173690796, 1.1051922302246093, 1.0416396495819091]}, 'ground': {'top1': [0.9825, 0.8993, 0.9589, 0.9528, 0.9763, 0.9553, 0.962, 0.9672, 0.9699, 0.969, 0.9742]}}\n",
      "resnet_basic_110 False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_True_lr_0.01_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_True_lr_0.01_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 3)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9603\n",
      "fgsm8   :  0.1484\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.096111492919922\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484], 'avg_loss_value': [6.096111492919922]}, 'ground': {'top1': [0.9603]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9267\n",
      "fgsm8   :  0.2834\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7953681743621825\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834], 'avg_loss_value': [6.096111492919922, 1.7953681743621825]}, 'ground': {'top1': [0.9603, 0.9267]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9294\n",
      "fgsm8   :  0.324\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.726015849494934\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9365\n",
      "fgsm8   :  0.3899\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5790198944091798\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9522\n",
      "fgsm8   :  0.422\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5354140899658204\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9411\n",
      "fgsm8   :  0.4208\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5731758352279663\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9515\n",
      "fgsm8   :  0.4368\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5536442516326905\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208, 0.4368], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663, 1.5536442516326905]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411, 0.9515]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9597\n",
      "fgsm8   :  0.4577\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4901687507629395\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208, 0.4368, 0.4577], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663, 1.5536442516326905, 1.4901687507629395]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411, 0.9515, 0.9597]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9555\n",
      "fgsm8   :  0.493\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3485121879577637\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208, 0.4368, 0.4577, 0.493], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663, 1.5536442516326905, 1.4901687507629395, 1.3485121879577637]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411, 0.9515, 0.9597, 0.9555]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9703\n",
      "fgsm8   :  0.4917\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3768732418060303\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208, 0.4368, 0.4577, 0.493, 0.4917], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663, 1.5536442516326905, 1.4901687507629395, 1.3485121879577637, 1.3768732418060303]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411, 0.9515, 0.9597, 0.9555, 0.9703]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9673\n",
      "fgsm8   :  0.4893\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3592001903533935\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1484, 0.2834, 0.324, 0.3899, 0.422, 0.4208, 0.4368, 0.4577, 0.493, 0.4917, 0.4893], 'avg_loss_value': [6.096111492919922, 1.7953681743621825, 1.726015849494934, 1.5790198944091798, 1.5354140899658204, 1.5731758352279663, 1.5536442516326905, 1.4901687507629395, 1.3485121879577637, 1.3768732418060303, 1.3592001903533935]}, 'ground': {'top1': [0.9603, 0.9267, 0.9294, 0.9365, 0.9522, 0.9411, 0.9515, 0.9597, 0.9555, 0.9703, 0.9673]}}\n",
      "resnet_basic_110 True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 76)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9832\n",
      "fgsm8   :  0.2358\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  3.07305129776001\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358], 'avg_loss_value': [3.07305129776001]}, 'ground': {'top1': [0.9832]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9285\n",
      "fgsm8   :  0.2964\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7837927989959717\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964], 'avg_loss_value': [3.07305129776001, 1.7837927989959717]}, 'ground': {'top1': [0.9832, 0.9285]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.926\n",
      "fgsm8   :  0.3796\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.661218316078186\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186]}, 'ground': {'top1': [0.9832, 0.9285, 0.926]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9386\n",
      "fgsm8   :  0.3836\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6497144916534423\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9475\n",
      "fgsm8   :  0.4424\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4826997108459472\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9545\n",
      "fgsm8   :  0.4331\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5175878761291504\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9459\n",
      "fgsm8   :  0.4351\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5809620840072631\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331, 0.4351], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504, 1.5809620840072631]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545, 0.9459]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9522\n",
      "fgsm8   :  0.4594\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4671422595977783\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331, 0.4351, 0.4594], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504, 1.5809620840072631, 1.4671422595977783]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545, 0.9459, 0.9522]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9692\n",
      "fgsm8   :  0.5083\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3297337076187135\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331, 0.4351, 0.4594, 0.5083], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504, 1.5809620840072631, 1.4671422595977783, 1.3297337076187135]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545, 0.9459, 0.9522, 0.9692]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9564\n",
      "fgsm8   :  0.4718\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.472599196243286\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331, 0.4351, 0.4594, 0.5083, 0.4718], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504, 1.5809620840072631, 1.4671422595977783, 1.3297337076187135, 1.472599196243286]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545, 0.9459, 0.9522, 0.9692, 0.9564]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9531\n",
      "fgsm8   :  0.5085\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.313908380126953\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.2358, 0.2964, 0.3796, 0.3836, 0.4424, 0.4331, 0.4351, 0.4594, 0.5083, 0.4718, 0.5085], 'avg_loss_value': [3.07305129776001, 1.7837927989959717, 1.661218316078186, 1.6497144916534423, 1.4826997108459472, 1.5175878761291504, 1.5809620840072631, 1.4671422595977783, 1.3297337076187135, 1.472599196243286, 1.313908380126953]}, 'ground': {'top1': [0.9832, 0.9285, 0.926, 0.9386, 0.9475, 0.9545, 0.9459, 0.9522, 0.9692, 0.9564, 0.9531]}}\n",
      "densenet_BC_100_12 False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 21)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9635\n",
      "fgsm8   :  0.1721\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.880070363616944\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721], 'avg_loss_value': [6.880070363616944]}, 'ground': {'top1': [0.9635]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9438\n",
      "fgsm8   :  0.3249\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7326869522094726\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249], 'avg_loss_value': [6.880070363616944, 1.7326869522094726]}, 'ground': {'top1': [0.9635, 0.9438]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9552\n",
      "fgsm8   :  0.4175\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.5537891805648805\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9602\n",
      "fgsm8   :  0.4392\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.4311112213134765\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9544\n",
      "fgsm8   :  0.4801\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.343136138534546\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9427\n",
      "fgsm8   :  0.5329\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.24089504737854\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9739\n",
      "fgsm8   :  0.5723\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.132014040184021\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329, 0.5723], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854, 1.132014040184021]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427, 0.9739]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9747\n",
      "fgsm8   :  0.6294\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.0252779691696168\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329, 0.5723, 0.6294], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854, 1.132014040184021, 1.0252779691696168]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427, 0.9739, 0.9747]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9679\n",
      "fgsm8   :  0.6875\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.8861511241912842\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329, 0.5723, 0.6294, 0.6875], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854, 1.132014040184021, 1.0252779691696168, 0.8861511241912842]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427, 0.9739, 0.9747, 0.9679]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9791\n",
      "fgsm8   :  0.7281\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.7619349742889404\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329, 0.5723, 0.6294, 0.6875, 0.7281], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854, 1.132014040184021, 1.0252779691696168, 0.8861511241912842, 0.7619349742889404]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427, 0.9739, 0.9747, 0.9679, 0.9791]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9775\n",
      "fgsm8   :  0.7226\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.7731637550354004\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.1721, 0.3249, 0.4175, 0.4392, 0.4801, 0.5329, 0.5723, 0.6294, 0.6875, 0.7281, 0.7226], 'avg_loss_value': [6.880070363616944, 1.7326869522094726, 1.5537891805648805, 1.4311112213134765, 1.343136138534546, 1.24089504737854, 1.132014040184021, 1.0252779691696168, 0.8861511241912842, 0.7619349742889404, 0.7731637550354004]}, 'ground': {'top1': [0.9635, 0.9438, 0.9552, 0.9602, 0.9544, 0.9427, 0.9739, 0.9747, 0.9679, 0.9791, 0.9775]}}\n",
      "densenet_BC_100_12 True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 123)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9838\n",
      "fgsm8   :  0.1917\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  3.016518826675415\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917], 'avg_loss_value': [3.016518826675415]}, 'ground': {'top1': [0.9838]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9496\n",
      "fgsm8   :  0.3725\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6655770797729492\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725], 'avg_loss_value': [3.016518826675415, 1.6655770797729492]}, 'ground': {'top1': [0.9838, 0.9496]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9693\n",
      "fgsm8   :  0.4783\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3718419736862182\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.959\n",
      "fgsm8   :  0.5049\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3148212268829347\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9637\n",
      "fgsm8   :  0.4999\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.3011380027770996\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9661\n",
      "fgsm8   :  0.5516\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.2061841646194458\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9657\n",
      "fgsm8   :  0.6624\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.9232718328475952\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516, 0.6624], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458, 0.9232718328475952]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661, 0.9657]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9783\n",
      "fgsm8   :  0.7208\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.7709575658798218\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516, 0.6624, 0.7208], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458, 0.9232718328475952, 0.7709575658798218]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661, 0.9657, 0.9783]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9755\n",
      "fgsm8   :  0.6986\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.8570742613792419\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516, 0.6624, 0.7208, 0.6986], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458, 0.9232718328475952, 0.7709575658798218, 0.8570742613792419]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661, 0.9657, 0.9783, 0.9755]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.973\n",
      "fgsm8   :  0.76\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.6683910976409912\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516, 0.6624, 0.7208, 0.6986, 0.76], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458, 0.9232718328475952, 0.7709575658798218, 0.8570742613792419, 0.6683910976409912]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661, 0.9657, 0.9783, 0.9755, 0.973]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9773\n",
      "fgsm8   :  0.8211\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  0.5026678398132324\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.1917, 0.3725, 0.4783, 0.5049, 0.4999, 0.5516, 0.6624, 0.7208, 0.6986, 0.76, 0.8211], 'avg_loss_value': [3.016518826675415, 1.6655770797729492, 1.3718419736862182, 1.3148212268829347, 1.3011380027770996, 1.2061841646194458, 0.9232718328475952, 0.7709575658798218, 0.8570742613792419, 0.6683910976409912, 0.5026678398132324]}, 'ground': {'top1': [0.9838, 0.9496, 0.9693, 0.959, 0.9637, 0.9661, 0.9657, 0.9783, 0.9755, 0.973, 0.9773]}}\n",
      "vgg_15_BN_64 False\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_True_lr_0.001_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_True_lr_0.001_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 38)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9607\n",
      "fgsm8   :  0.0647\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  7.937725462341309\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647], 'avg_loss_value': [7.937725462341309]}, 'ground': {'top1': [0.9607]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8941\n",
      "fgsm8   :  0.1945\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.1601324310302736\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945], 'avg_loss_value': [7.937725462341309, 2.1601324310302736]}, 'ground': {'top1': [0.9607, 0.8941]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8897\n",
      "fgsm8   :  0.2408\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.9685302684783936\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9208\n",
      "fgsm8   :  0.2825\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.8662936737060547\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9083\n",
      "fgsm8   :  0.3129\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.785239829826355\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9277\n",
      "fgsm8   :  0.3587\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6680635311126708\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9011\n",
      "fgsm8   :  0.3243\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7479740461349487\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587, 0.3243], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708, 1.7479740461349487]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277, 0.9011]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9449\n",
      "fgsm8   :  0.4143\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.607247014427185\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587, 0.3243, 0.4143], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708, 1.7479740461349487, 1.607247014427185]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277, 0.9011, 0.9449]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9564\n",
      "fgsm8   :  0.3802\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6787986948013305\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587, 0.3243, 0.4143, 0.3802], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708, 1.7479740461349487, 1.607247014427185, 1.6787986948013305]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277, 0.9011, 0.9449, 0.9564]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9029\n",
      "fgsm8   :  0.378\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7100901109695434\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587, 0.3243, 0.4143, 0.3802, 0.378], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708, 1.7479740461349487, 1.607247014427185, 1.6787986948013305, 1.7100901109695434]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277, 0.9011, 0.9449, 0.9564, 0.9029]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9367\n",
      "fgsm8   :  0.4318\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.536122541809082\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': [0.0647, 0.1945, 0.2408, 0.2825, 0.3129, 0.3587, 0.3243, 0.4143, 0.3802, 0.378, 0.4318], 'avg_loss_value': [7.937725462341309, 2.1601324310302736, 1.9685302684783936, 1.8662936737060547, 1.785239829826355, 1.6680635311126708, 1.7479740461349487, 1.607247014427185, 1.6787986948013305, 1.7100901109695434, 1.536122541809082]}, 'ground': {'top1': [0.9607, 0.8941, 0.8897, 0.9208, 0.9083, 0.9277, 0.9011, 0.9449, 0.9564, 0.9029, 0.9367]}}\n",
      "vgg_15_BN_64 True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 86)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9807\n",
      "fgsm8   :  0.0746\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.090551660919189\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746], 'avg_loss_value': [4.090551660919189]}, 'ground': {'top1': [0.9807]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.8732\n",
      "fgsm8   :  0.2326\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.9888192844390868\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326], 'avg_loss_value': [4.090551660919189, 1.9888192844390868]}, 'ground': {'top1': [0.9807, 0.8732]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9093\n",
      "fgsm8   :  0.2213\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.033395997428894\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9161\n",
      "fgsm8   :  0.2537\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.9993327297210692\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9318\n",
      "fgsm8   :  0.2765\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.794531685447693\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9354\n",
      "fgsm8   :  0.3407\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7679521532058715\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9313\n",
      "fgsm8   :  0.3668\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.7461462682723998\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407, 0.3668], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715, 1.7461462682723998]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354, 0.9313]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9401\n",
      "fgsm8   :  0.4241\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6287242708206178\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407, 0.3668, 0.4241], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715, 1.7461462682723998, 1.6287242708206178]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354, 0.9313, 0.9401]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.947\n",
      "fgsm8   :  0.4183\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.6064173309326173\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407, 0.3668, 0.4241, 0.4183], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715, 1.7461462682723998, 1.6287242708206178, 1.6064173309326173]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354, 0.9313, 0.9401, 0.947]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9486\n",
      "fgsm8   :  0.4486\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.535470973968506\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407, 0.3668, 0.4241, 0.4183, 0.4486], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715, 1.7461462682723998, 1.6287242708206178, 1.6064173309326173, 1.535470973968506]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354, 0.9313, 0.9401, 0.947, 0.9486]}}\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9566\n",
      "fgsm8   :  0.4412\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  1.551829870414734\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': [0.0746, 0.2326, 0.2213, 0.2537, 0.2765, 0.3407, 0.3668, 0.4241, 0.4183, 0.4486, 0.4412], 'avg_loss_value': [4.090551660919189, 1.9888192844390868, 2.033395997428894, 1.9993327297210692, 1.794531685447693, 1.7679521532058715, 1.7461462682723998, 1.6287242708206178, 1.6064173309326173, 1.535470973968506, 1.551829870414734]}, 'ground': {'top1': [0.9807, 0.8732, 0.9093, 0.9161, 0.9318, 0.9354, 0.9313, 0.9401, 0.947, 0.9486, 0.9566]}}\n",
      "resnext_29_8x64d True\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_False_lr_0.001_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_False_lr_0.001_seed_0/model_best_state_c10h_val_loss.pth' (epoch 57)\n",
      "Files already downloaded and verified\n",
      "WARNING: using validation as train and val currently as a test!! turn off later!\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-147cb50e31e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m         ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, attack_ensemble, \n\u001b[1;32m     79\u001b[0m                                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                                                          num_minibatches=n_val_batches)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/adversarial_evaluation.py\u001b[0m in \u001b[0;36mevaluate_ensemble\u001b[0;34m(self, data_loader, attack_ensemble, skip_ground, verbose, num_minibatches)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t (mb: %s) evaluating %s...\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattack_ensemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/adversarial_evaluation.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, examples, labels)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mattack_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/adversarial_training.py\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m     89\u001b[0m         perturbation = self.adv_attack_obj.attack(adv_inputs.data,\n\u001b[1;32m     90\u001b[0m                                                   \u001b[0mpre_adv_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                                   **self.attack_kwargs)\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0madv_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/adversarial_attacks.py\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, examples, labels, step_size, verbose)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# take gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         loss = self.loss_fxn.forward(perturbation(var_examples), var_labels,\n\u001b[0;32m--> 218\u001b[0;31m                                      perturbation=perturbation)\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/loss_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, examples, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mscalar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;31m# assert scalar is either a...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             assert (isinstance(scalar, float) or # number\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/loss_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, examples, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mxentropy_init_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reduction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mxentropy_init_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m##############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/pytorch_image_classification_models/resnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/pytorch_image_classification_models/resnext.py\u001b[0m in \u001b[0;36m_forward_conv\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tigress/joshuacp/projects/cifar10-human-experiments/mister_ed_newer/pytorch_image_classification_models/resnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# not apply ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "# model_meta = get_meta(verbose=False, filt='dense')\n",
    "model_meta = get_meta(verbose=False)\n",
    "\n",
    "config_folder = '/tigress/ruairidh/model_results/optimal_training_run'\n",
    "break_loop = False\n",
    "epochs_per_model = 10 #10\n",
    "verbosity='low'# 'snoop' # 'low'\n",
    "\n",
    "batch_size = 128\n",
    "n_val_batches = int(np.ceil(10000/float(batch_size)))\n",
    "#n_val_batches = 100\n",
    "save_results = True\n",
    "\n",
    "for mm in model_meta:\n",
    "    \n",
    "    print(mm['model_name'], mm['human'])\n",
    "    print('')\n",
    "    \n",
    "    config = parse_args(arch=mm['arch'], \n",
    "                        mdl_config=os.path.join(config_folder,\n",
    "                                                mm['model_name'],\n",
    "                                                'config.json'))\n",
    "    \n",
    "    resume_path = os.path.join(root, \n",
    "                               mm['model_name'],\n",
    "                               mm['param_folder'],\n",
    "                               mm['pth_file'])\n",
    "\n",
    "    model = load_our_model(config, resume_path)\n",
    "    \n",
    "    delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "    attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "    attack_object = aa.FGSM(model, normalizer, delta_threat, attack_loss)\n",
    "    attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "    attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                         attack_specific_params={'attack_kwargs': attack_kwargs})\n",
    "    experiment_name = 'test'\n",
    "    architecture = 'test'\n",
    "    training_obj = advtrain.AdversarialTraining(model, normalizer, experiment_name, architecture)\n",
    "    \n",
    "    train_loss = nn.CrossEntropyLoss() # just use standard XEntropy to train\n",
    "    \n",
    "    for epoch in range(epochs_per_model + 1):\n",
    "        \n",
    "        cifar_trainset = cifar_loader.load_cifar_data('val', batch_size=batch_size)\n",
    "        print('WARNING: using validation as train and val currently as a test!! turn off later!')\n",
    "        cifar_valset = cifar_loader.load_cifar_data('val', batch_size=batch_size)\n",
    "        \n",
    "        if epoch != 0:\n",
    "            training_obj.train(cifar_trainset, 1, train_loss, \n",
    "                               attack_parameters=attack_params,\n",
    "                               verbosity=verbosity)\n",
    "\n",
    "        ### EVAL !!! ###\n",
    "        adv_eval_object = adveval.AdversarialEvaluation(model, normalizer)\n",
    "        to_eval_dict = {'top1': 'top1', \n",
    "                        'avg_loss_value': 'avg_loss_value'}\n",
    "\n",
    "        \n",
    "        #------ FGSM8 Block \n",
    "        linf_8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                         'lp_bound': 8.0 / 255.0})\n",
    "        fgsm8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                         'lp_bound': 8.0/ 255.0})\n",
    "        fgsm8_attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "        fgsm8_attack = aa.FGSM(model, normalizer, linf_8_threat, fgsm8_attack_loss)\n",
    "        fgsm8_attack_kwargs = {'verbose': False}\n",
    "        fgsm8_attack_params = advtrain.AdversarialAttackParameters(fgsm8_attack,\n",
    "                                                                   attack_specific_params=\n",
    "                                                                   {'attack_kwargs': fgsm8_attack_kwargs})\n",
    "        \n",
    "        fgsm8_eval = adveval.EvaluationResult(fgsm8_attack_params, \n",
    "                                              to_eval=to_eval_dict)\n",
    "        attack_ensemble = {'fgsm8': fgsm8_eval}\n",
    "\n",
    "        ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, attack_ensemble, \n",
    "                                                         verbose=False, \n",
    "                                                         num_minibatches=n_val_batches)\n",
    "\n",
    "\n",
    "\n",
    "        sort_order = {'ground': 1, 'fgsm8': 2, 'pgd4': 3, 'pgd8': 4}\n",
    "        def pretty_printer(eval_ensemble, result_type):\n",
    "            print('~' * 10, result_type, '~' * 10)\n",
    "            for key in sorted(list(eval_ensemble.keys()), key=lambda k: sort_order[k]):\n",
    "                eval_result = eval_ensemble[key]\n",
    "                pad = 6 - len(key)\n",
    "                if result_type not in eval_result.results:\n",
    "                    continue \n",
    "                avg_result = eval_result.results[result_type].avg\n",
    "                print(key, pad* ' ', ': ', avg_result)\n",
    "\n",
    "        print('')\n",
    "        pretty_printer(ensemble_out, 'top1')\n",
    "        pretty_printer(ensemble_out, 'avg_loss_value')\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        for ae_key in attack_ensemble.keys():\n",
    "            if ae_key not in mm.keys():\n",
    "                mm[ae_key] = {}\n",
    "            for e_key in to_eval_dict.keys():\n",
    "                if e_key not in mm[ae_key].keys() and (e_key in ensemble_out[ae_key].results.keys()):\n",
    "                    mm[ae_key][e_key] = []\n",
    "                try:\n",
    "                    mm[ae_key][e_key].append(ensemble_out[ae_key].results[e_key].avg)\n",
    "                except:\n",
    "                    pass\n",
    "        print(mm)\n",
    "\n",
    "        if break_loop: break\n",
    "        if save_results: \n",
    "            pickle.dump(model_meta, open('fgsm_defense_results_SLOW.pickle','wb'))\n",
    "            \n",
    "    del model\n",
    "    del ensemble_out, training_obj, fgsm8_eval\n",
    "    del cifar_trainset, cifar_valset\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d77071facfbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_plot_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_plot_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuman\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fgsm8'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot_all = pd.DataFrame(model_meta)\n",
    "\n",
    "plot_key = 'avg_loss_value' #'top1' #\n",
    "\n",
    "plt.figure(figsize=(4,4), dpi=150)\n",
    "for i, mn in enumerate(df_plot_all.model_name.unique()):\n",
    "    \n",
    "    df_plot = df_plot_all[df_plot_all.model_name==mn].copy()\n",
    "\n",
    "    y = df_plot[df_plot.human==False]['fgsm8'].values[0][plot_key]\n",
    "    x = np.arange(len(y))\n",
    "#     print(y)\n",
    "    if i == 0:\n",
    "        plt.plot(x, y, color='red', linewidth=1, label='C10 Training')\n",
    "    else:\n",
    "        plt.plot(x, y, color='red', linewidth=1)\n",
    "\n",
    "    df_plot = df_plot_all[df_plot_all.model_name==mn].copy()\n",
    "\n",
    "    y = df_plot[df_plot.human==True]['fgsm8'].values[0][plot_key]\n",
    "    x = np.arange(len(y))\n",
    "#     print(y)\n",
    "    if i == 0:\n",
    "        plt.plot(x, y, color='blue', linewidth=1, label='C10H Training')\n",
    "    else:\n",
    "        plt.plot(x, y, color='blue', linewidth=1)\n",
    "        \n",
    "\n",
    "# plt.xlim([0,9])\n",
    "# plt.ylim([0,32])\n",
    "\n",
    "plt.xticks(range(10), range(1, 11))\n",
    "\n",
    "plt.ylabel('Crossentropy')\n",
    "plt.xlabel('PGD Iteration')\n",
    "\n",
    "plt.legend(edgecolor='black', fancybox=False)\n",
    "# plt.savefig('defense_training.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define what we want to do here:\n",
    "\n",
    "Our goal is to run through a few training epochs of a pretrained classifier where we augment the training data with a set of adversarial examples. For simplicity's sake, let's just try and train a few epochs of a 20-layer ResNet trained on CIFAR-10, defended against an FGSM attack of $\\epsilon=8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's instatiate our pretrained classifier and our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_trainset = cifar_loader.load_cifar_data('train')\n",
    "model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's build the attack parameters: an object that contains all the information to perform an attack on a minibatch. So first let's build an attack object and then furnish it with the necessary kwargs. \n",
    "\n",
    "Like in tutorial 1, to create an attack object, we'll need to create a threat model and a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "attack_object = aa.FGSM(model, normalizer, delta_threat, attack_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we build the `AttackParameters` object, which just wraps the attack object with the kwargs needed to call the `attack(...)` method on attack. For FGSM attacks, we just want to turn the verbosity off, but for more complicated attacks, this will be more involved. Typically in training, we generate a single adversarial example per training point, but to be speedy here, let's only create 1 example per every 5 training points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our attack parameters built, we can build the object that handles training for us: this is instatiated with knowledge of the classifier, normalizer and some identifying features such as the *name* of the experiment and architecture. It's worthwhile to be informative with these so you keep which attacks this model is trained against straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'tutorial_fgsm'\n",
    "architecture = 'resnet20'\n",
    "training_obj = advtrain.AdversarialTraining(model, normalizer, experiment_name, architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you start training though, you'll need to furnish the trainer with some extra arguments:\n",
    "    - the data loader \n",
    "    - the number of epochs to train for \n",
    "    - a loss function (not one of the `mister_ed` custom loss functions though!)\n",
    "    - which optimizer to use (defaults to Adam with decent hyperparams)\n",
    "    - the attack parameters object \n",
    "    - whether or not to use the gpu (defaults to not using GPU)\n",
    "    - the verbosity level (ranging from ['low', 'medium', 'high', 'snoop'] (defaults to 'medium')\n",
    "    - whether or not to save the generated adversarial examples as images (defaults to false)\n",
    "    \n",
    "To be cute, we'll just train for two epochs so you get the picture. Also note that unless the verbosity is set to `low`, a checkpoint will be saved after every epoch. By default, these checkpoints are named like `<experiment_name>.<architecture_name>.<epoch>.path.tar`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = nn.CrossEntropyLoss() # just use standard XEntropy to train\n",
    "_ = training_obj.train(cifar_trainset, 10, train_loss, \n",
    "                   attack_parameters=attack_params,\n",
    "                   verbosity='snoop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printouts look like:\n",
    "``` \n",
    "[epoch_no, minibatch_no] accuracy: (X, Y) \n",
    "[epoch_no, minibatch_no] loss: Z\n",
    "```\n",
    "\n",
    "- X is the percent of successfully classified *adversarial* examples generated from that minibatch only\n",
    "- Y is the percent of successfully classified *original* examples on that minibatch only\n",
    "- Z is the value of the loss function after that minibatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training completes, you can verify that the checkpoints are indeed stored in wherever you have set up pretrained models to be stored. By default this is `mister_ed/pretrained_models/`, so you should have a `tutorial_fgsm.resnet20.000002.path.tar` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restarting from Checkpoint\n",
    "When training, sometimes @#\\$& happens and things break. This is why we checkpoint. Here we'll show how to restart from checkpoint in training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to pick back up from where we left off with the experiment/architecture pair defined above `(tutorial_fgsm, resnet20)`. Then we want to do the following steps:\n",
    "\n",
    "1. Instantiate a model of the same architecture (weights don't matter, since we'll load from the checkpoint) \n",
    "2. Build an `AdversarialTraining` object using this model, its normalizer, and the same experiment name, architecture name \n",
    "3. Build a loss function, attack_parameters object, and all other identical kwargs from the first (aborted) training run \n",
    "4. Run the training using the training object's `train_from_checkpoint` method instead of `train`. All the kwargs are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True)\n",
    "new_train_obj = advtrain.AdversarialTraining(naive_model, normalizer, experiment_name, architecture)\n",
    "\n",
    "delta_threat = ap.ThreatModel(ap.DeltaAddition, \n",
    "                              {'lp_style': 'inf', \n",
    "                               'lp_bound': 8.0 / 255})\n",
    "attack_loss = plf.VanillaXentropy(naive_model, normalizer)\n",
    "attack_object = aa.FGSM(naive_model, normalizer, delta_threat, attack_loss)\n",
    "attack_kwargs = {'verbose': False} # kwargs to be called in attack_object.attack(...)\n",
    "attack_params = advtrain.AdversarialAttackParameters(attack_object, proportion_attacked=0.2, \n",
    "                                                     attack_specific_params={'attack_kwargs': attack_kwargs})\n",
    "\n",
    "new_train_obj.train_from_checkpoint(cifar_trainset, 4, train_loss, attack_parameters=attack_params, \n",
    "                                    verbosity='high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this finishes, notice that you should now have a file \n",
    "`tutorial_fgsm.resnet20.000004.path.tar` in your pretrained_models directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the training script \n",
    "Using an ipython notebook isn't typically ideal for training, since it mandates you keep your browser window open. To this end, we've built a script to perform adversarial training in a tmux/screen background. This is located in `scripts/advtrain.py`. Here's what we've found are best practices for doing this:\n",
    "\n",
    "- Copy `scripts/advtrain.py` into `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py`\n",
    "- Modify the `build_attack_params` method in `scripts/advtrain_<DESCRIPTIVE_EXPERIMENT_NAME>.py` to use the attack parameters that you want. There's plenty of prebuilt attack parameters in that file to choose from. \n",
    "- In a tmux/screen, from `mister_ed`, run \n",
    "\n",
    "```python -m scripts.advtrain_DESCRIPTIVE_EXPERIMENT_NAME --exp <DESCRIPTIVE_EXPERIMENT_NAME> --arch <ARCHITECTURE_CHOICE> --verbosity [snoop/high/medium]```\n",
    "\n",
    "- To resume, you can optionally add the `-r` or `--resume` flag to the script call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on GPU Usage\n",
    "If you have access to a GPU on your machine, you'll probably want to leverage its power when doing training and attacks. `mister_ed` has been designed so \"standard\" GPU behavior should be supported without any extra effort. By \"standard\" GPU behavior, I mean that all objects reside on the same device: either all on the GPU or none on the GPU. If there is a GPU on your machine, which one can check from the output of \n",
    "```\n",
    "import torch.cuda as cuda \n",
    "print(cuda.is_available()) \n",
    "```\n",
    "Globally, unless otherwise specified, all objects will be initialized in GPU-mode if this output is `True`. This is done behind-the-scenes by setting the environment variable `MISTER_ED_GPU`. If you have access to a GPU, but wouldn't like to use it, you can manually override this environment variable by calling:\n",
    "```\n",
    "import utils.pytorch_utils as utils \n",
    "utils.set_global_gpu(False)\n",
    "```\n",
    "And then none of your objects will be in GPU-mode by default. \n",
    "\n",
    "For nonstandard GPU behavior, you should initialize any object that differs from the default gpu status (as defined by `MISTER_ED_GPU`) with the kwarg `manual_gpu=<True/False>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
