{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "\n",
    "# EXTERNAL LIBRARY IMPORTS\n",
    "import numpy as np \n",
    "import scipy \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch # Need torch version >=0.3\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "assert float(torch.__version__[:3]) >= 0.3\n",
    "\n",
    "# MISTER ED SPECIFIC IMPORT BLOCK\n",
    "# (here we do things so relative imports work )\n",
    "# Universal import block \n",
    "# Block to get the relative imports working \n",
    "import os, sys, re, gc, pickle\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import config\n",
    "import prebuilt_loss_functions as plf\n",
    "import loss_functions as lf \n",
    "import utils.pytorch_utils as utils\n",
    "import utils.image_utils as img_utils\n",
    "import cifar10.cifar_loader as cifar_loader\n",
    "import cifar10.cifar_resnets as cifar_resnets\n",
    "import adversarial_training as advtrain\n",
    "import adversarial_evaluation as adveval\n",
    "import utils.checkpoints as checkpoints\n",
    "import adversarial_perturbations as ap \n",
    "import adversarial_attacks as aa\n",
    "import spatial_transformers as st\n",
    "\n",
    "### START pytorch_image_classification imports\n",
    "import time, random, json, logging, argparse, csv\n",
    "from pytorch_image_classification_dataloader_c10h import get_loader\n",
    "from pytorch_image_classification_utils import (str2bool, load_model, save_checkpoint, create_optimizer,\n",
    "                                                AverageMeter, mixup, CrossEntropyLoss, onehot)\n",
    "# from rutils_run import save_checkpoint_epoch\n",
    "from pytorch_image_classification_argparser import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "\n",
    "def parse_args(arch, mdl_config):\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--arch', type=str, default='resnet')\n",
    "    parser.add_argument('--arch', type=str, default=arch)\n",
    "    # parser.add_argument('--config', type=str, default='tmp_reference_model/resnet_basic_110_config.json')\n",
    "    parser.add_argument('--config', type=str, default=mdl_config)\n",
    "    # model config (VGG)\n",
    "    parser.add_argument('--n_channels', type=str)\n",
    "    parser.add_argument('--n_layers', type=str)\n",
    "    parser.add_argument('--use_bn', type=str2bool)\n",
    "    #\n",
    "    parser.add_argument('--base_channels', type=int)\n",
    "    parser.add_argument('--block_type', type=str)\n",
    "    parser.add_argument('--depth', type=int)\n",
    "    # model config (ResNet-preact)\n",
    "    parser.add_argument('--remove_first_relu', type=str2bool)\n",
    "    parser.add_argument('--add_last_bn', type=str2bool)\n",
    "    parser.add_argument('--preact_stage', type=str)\n",
    "    # model config (WRN)\n",
    "    parser.add_argument('--widening_factor', type=int)\n",
    "    # model config (DenseNet)\n",
    "    parser.add_argument('--growth_rate', type=int)\n",
    "    parser.add_argument('--compression_rate', type=float)\n",
    "    # model config (WRN, DenseNet)\n",
    "    parser.add_argument('--drop_rate', type=float)\n",
    "    # model config (PyramidNet)\n",
    "    parser.add_argument('--pyramid_alpha', type=int)\n",
    "    # model config (ResNeXt)\n",
    "    parser.add_argument('--cardinality', type=int)\n",
    "    # model config (shake-shake)\n",
    "    parser.add_argument('--shake_forward', type=str2bool)\n",
    "    parser.add_argument('--shake_backward', type=str2bool)\n",
    "    parser.add_argument('--shake_image', type=str2bool)\n",
    "    # model config (SENet)\n",
    "    parser.add_argument('--se_reduction', type=int)\n",
    "\n",
    "    parser.add_argument('--outdir', type=str, required=False)\n",
    "    parser.add_argument('--seed', type=int, default=17)\n",
    "    parser.add_argument('--test_first', type=str2bool, default=True)\n",
    "    parser.add_argument('--gpu', type=str, default='0') # -1 for CPU\n",
    "    # TensorBoard configuration\n",
    "    parser.add_argument(\n",
    "        '--tensorboard', dest='tensorboard', action='store_true', default=True)\n",
    "    parser.add_argument(\n",
    "        '--no-tensorboard', dest='tensorboard', action='store_false')\n",
    "    parser.add_argument('--tensorboard_train_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_test_images', action='store_true')\n",
    "    parser.add_argument('--tensorboard_model_params', action='store_true')\n",
    "    # configuration of optimizer\n",
    "    parser.add_argument('--epochs', type=int)\n",
    "    parser.add_argument('--batch_size', type=int, default=500)\n",
    "    parser.add_argument('--optimizer', type=str, choices=['sgd', 'adam'])\n",
    "    parser.add_argument('--base_lr', type=float)\n",
    "    parser.add_argument('--weight_decay', type=float)\n",
    "    # configuration for SGD\n",
    "    parser.add_argument('--momentum', type=float)\n",
    "    parser.add_argument('--nesterov', type=str2bool)\n",
    "    # configuration for learning rate scheduler\n",
    "    parser.add_argument(\n",
    "        '--scheduler', type=str, choices=['none', 'multistep', 'cosine'])\n",
    "    # configuration for multi-step scheduler]\n",
    "    parser.add_argument('--milestones', type=str)\n",
    "    parser.add_argument('--lr_decay', type=float)\n",
    "    # configuration for cosine-annealing scheduler]\n",
    "    parser.add_argument('--lr_min', type=float, default=0)\n",
    "    # configuration for Adam\n",
    "    parser.add_argument('--betas', type=str)\n",
    "    # configuration of data loader\n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default='CIFAR10H',\n",
    "        choices=['CIFAR10', 'CIFAR10H'])\n",
    "    parser.add_argument('--num_workers', type=int, default=7)\n",
    "    # cutout configuration\n",
    "    parser.add_argument('--use_cutout', action='store_true', default=False)\n",
    "    parser.add_argument('--cutout_size', type=int, default=16)\n",
    "    parser.add_argument('--cutout_prob', type=float, default=1)\n",
    "    parser.add_argument('--cutout_inside', action='store_true', default=False)\n",
    "    # random erasing configuration\n",
    "    parser.add_argument(\n",
    "        '--use_random_erasing', action='store_true', default=False)\n",
    "    parser.add_argument('--random_erasing_prob', type=float, default=0.5)\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_area_ratio_range', type=str, default='[0.02, 0.4]')\n",
    "    parser.add_argument(\n",
    "        '--random_erasing_min_aspect_ratio', type=float, default=0.3)\n",
    "    parser.add_argument('--random_erasing_max_attempt', type=int, default=20)\n",
    "    # mixup configuration\n",
    "    parser.add_argument('--use_mixup', action='store_true', default=False)\n",
    "    parser.add_argument('--mixup_alpha', type=float, default=1)\n",
    "\n",
    "    # previous model weights to load if any\n",
    "    parser.add_argument('--resume', type=str)\n",
    "    # whether to tune to human labels\n",
    "    parser.add_argument('--human_tune', action='store_true', default=False)\n",
    "    # where to save the loss/accuracy for c10h to a csv file\n",
    "    parser.add_argument('--c10h_scores_outdir', type=str, default='tmp')\n",
    "    # c10h scores save interval (in epochs)\n",
    "    parser.add_argument('--c10h_save_interval', type=str, default='1') # changed from int\n",
    "    # how much of the data to use use for test for c10h training\n",
    "    parser.add_argument('--c10h_testsplit_percent', type=float, default=0.1)\n",
    "    # seed for splitting the c10h data into train/test\n",
    "    parser.add_argument('--c10h_datasplit_seed', type=int, default=999)\n",
    "    # whether to use the cifar10 labels for the human test set (CONTROL)\n",
    "    parser.add_argument('--nonhuman_control', type=str2bool, default=False)\n",
    "    # whether to sample from the human labels to get one-hot samples\n",
    "    parser.add_argument('--c10h_sample', action='store_true', default=False)\n",
    "    # whether to save to out_dir\n",
    "    parser.add_argument('--no_output', action='store_true', default=False)\n",
    "    # to test the loaded model and don't train\n",
    "    parser.add_argument('--test_only', action='store_true', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    # if not is_tensorboard_available:\n",
    "    args.tensorboard = False\n",
    "\n",
    "    config = get_config(args)\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_our_model(config, weights_path):\n",
    "        \n",
    "    our_model = load_model(config['model_config'])\n",
    "    \n",
    "    # load pretrained weights if given\n",
    "    if os.path.isfile(weights_path):\n",
    "        print(\"=> loading checkpoint '{}'\".format(weights_path))\n",
    "\n",
    "        # Resolve CPU/GPU stuff\n",
    "        if use_gpu:\n",
    "            map_location = None\n",
    "        else:\n",
    "            map_location= (lambda s, l: s)\n",
    "\n",
    "        checkpoint = torch.load(weights_path,\n",
    "                                map_location=map_location)\n",
    "\n",
    "        correct_state_dict = {re.sub(r'^module\\.', '', k): v for k, v in\n",
    "                              checkpoint['state_dict'].items()}\n",
    "\n",
    "        our_model.load_state_dict(correct_state_dict)\n",
    "\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(weights_path, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(weights_path))\n",
    "        \n",
    "    return our_model\n",
    "\n",
    "# model = load_our_model(config, run_config['resume'])\n",
    "\n",
    "# cifar_valset = cifar_loader.load_cifar_data('val', batch_size=32)\n",
    "\n",
    "# _, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=32, use_gpu=use_gpu,\n",
    "#                                                           return_normalizer=True)\n",
    "_, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20,\n",
    "                                                          return_normalizer=True)\n",
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'resnext', 'model_name': 'resnext_29_8x64d', 'param_folder': 'con_False_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'resnext', 'model_name': 'resnext_29_8x64d', 'param_folder': 'con_True_lr_0.00001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'wrn', 'model_name': 'wrn_28_10', 'param_folder': 'con_True_lr_0.001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'wrn', 'model_name': 'wrn_28_10', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n",
      "{'arch': 'pyramidnet', 'model_name': 'pyramidnet_basic_110_270', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False}\n",
      "{'arch': 'pyramidnet', 'model_name': 'pyramidnet_basic_110_270', 'param_folder': 'con_False_lr_0.1_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True}\n"
     ]
    }
   ],
   "source": [
    "root = '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/'\n",
    "\n",
    "def get_arch(name):\n",
    "    if 'vgg_15_BN_64' in name: return 'vgg'\n",
    "    if 'resnet_basic_110' in name: return 'resnet' \n",
    "    if 'resnet_preact_bottleneck_164' in name: return 'resnet_preact' \n",
    "    if 'wrn_28_10' in name: return 'wrn' \n",
    "    if 'densenet_BC_100_12' in name: return 'densenet' \n",
    "    if 'pyramidnet_basic_110_270' in name: return 'pyramidnet' \n",
    "    if 'resnext_29_8x64d' in name: return 'resnext' \n",
    "    if 'shake_shake_26_2x64d_SSI_cutout16' in name: return 'shake_shake'\n",
    "    return 'NOT FOUND!!!'\n",
    "\n",
    "def get_meta(verbose=False, filt=None):\n",
    "    model_meta = []\n",
    "    for folder in os.listdir(root):\n",
    "        if filt: \n",
    "            if filt not in folder: break\n",
    "        param_folders = os.listdir(os.path.join(root, folder))\n",
    "        for param_folder in param_folders:\n",
    "            pth_file = os.listdir(os.path.join(root, folder, param_folder))[0]\n",
    "            meta = {}\n",
    "            meta['arch'] = get_arch(folder)\n",
    "            meta['model_name'] = folder\n",
    "            meta['param_folder'] = param_folder\n",
    "            meta['pth_file'] = pth_file\n",
    "            if 'con_True' in param_folder:\n",
    "                meta['human'] = False\n",
    "            else:\n",
    "                meta['human'] = True  \n",
    "\n",
    "            model_meta.append(meta)\n",
    "            if verbose: print(meta)\n",
    "    return model_meta\n",
    "\n",
    "# model_meta = get_meta(verbose=True, filt='shake_shake')\n",
    "model_meta = get_meta(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "shake_shake_26_2x64d_SSI_cutout16 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth' (epoch 123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuacp/anaconda3/lib/python3.6/site-packages/skimage/util/arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9875\n",
      "fgsm8   :  0.3945\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.030575957298279\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.0434574058042086\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.3945, 'avg_loss_value': 4.030575957298279, 'avg_successful_ssim': 0.0434574058042086}, 'ground': {'top1': 0.9875}}\n",
      "Files already downloaded and verified\n",
      "shake_shake_26_2x64d_SSI_cutout16 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 69)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.989\n",
      "fgsm8   :  0.3854\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.091712098121643\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043293468786753636\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.3854, 'avg_loss_value': 2.091712098121643, 'avg_successful_ssim': 0.043293468786753636}, 'ground': {'top1': 0.989}}\n",
      "Files already downloaded and verified\n",
      "resnet_preact_bottleneck_164 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_True_lr_0.001_seed_2/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_True_lr_0.001_seed_2/model_best_state_c10h_val_c10_loss.pth' (epoch 33)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9777\n",
      "fgsm8   :  0.1718\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.345359029769898\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.0429700559969828\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_True_lr_0.001_seed_2', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.1718, 'avg_loss_value': 6.345359029769898, 'avg_successful_ssim': 0.0429700559969828}, 'ground': {'top1': 0.9777}}\n",
      "Files already downloaded and verified\n",
      "resnet_preact_bottleneck_164 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_False_lr_0.1_seed_1/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_preact_bottleneck_164/con_False_lr_0.1_seed_1/model_best_state_c10h_val_loss.pth' (epoch 115)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9829\n",
      "fgsm8   :  0.2939\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.5579792928695677\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04284412503570629\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnet_preact', 'model_name': 'resnet_preact_bottleneck_164', 'param_folder': 'con_False_lr_0.1_seed_1', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.2939, 'avg_loss_value': 2.5579792928695677, 'avg_successful_ssim': 0.04284412503570629}, 'ground': {'top1': 0.9829}}\n",
      "Files already downloaded and verified\n",
      "resnet_basic_110 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_True_lr_0.01_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_True_lr_0.01_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 3)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9604\n",
      "fgsm8   :  0.1468\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.126165280342102\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04307304849991969\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_True_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.1468, 'avg_loss_value': 6.126165280342102, 'avg_successful_ssim': 0.04307304849991969}, 'ground': {'top1': 0.9604}}\n",
      "Files already downloaded and verified\n",
      "resnet_basic_110 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnet_basic_110/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 76)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9811\n",
      "fgsm8   :  0.2349\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  3.0770627808570863\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043152804005220986\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnet', 'model_name': 'resnet_basic_110', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.2349, 'avg_loss_value': 3.0770627808570863, 'avg_successful_ssim': 0.043152804005220986}, 'ground': {'top1': 0.9811}}\n",
      "Files already downloaded and verified\n",
      "densenet_BC_100_12 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 21)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9653\n",
      "fgsm8   :  0.165\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.892376618385315\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04332168281712333\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.165, 'avg_loss_value': 6.892376618385315, 'avg_successful_ssim': 0.04332168281712333}, 'ground': {'top1': 0.9653}}\n",
      "Files already downloaded and verified\n",
      "densenet_BC_100_12 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/densenet_BC_100_12/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 123)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9841\n",
      "fgsm8   :  0.1944\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  3.028488121032715\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04264860126343155\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'densenet', 'model_name': 'densenet_BC_100_12', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.1944, 'avg_loss_value': 3.028488121032715, 'avg_successful_ssim': 0.04264860126343155}, 'ground': {'top1': 0.9841}}\n",
      "Files already downloaded and verified\n",
      "vgg_15_BN_64 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_True_lr_0.001_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_True_lr_0.001_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 38)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9635\n",
      "fgsm8   :  0.0654\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  7.944105277061462\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043290767221451115\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_True_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.0654, 'avg_loss_value': 7.944105277061462, 'avg_successful_ssim': 0.043290767221451115}, 'ground': {'top1': 0.9635}}\n",
      "Files already downloaded and verified\n",
      "vgg_15_BN_64 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/vgg_15_BN_64/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 86)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9792\n",
      "fgsm8   :  0.0806\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.08302312374115\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043275029180260216\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'vgg', 'model_name': 'vgg_15_BN_64', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.0806, 'avg_loss_value': 4.08302312374115, 'avg_successful_ssim': 0.043275029180260216}, 'ground': {'top1': 0.9792}}\n",
      "Files already downloaded and verified\n",
      "resnext_29_8x64d True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_False_lr_0.001_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_False_lr_0.001_seed_0/model_best_state_c10h_val_loss.pth' (epoch 57)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9866\n",
      "fgsm8   :  0.2441\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.7033528184890745\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04318400819830065\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnext', 'model_name': 'resnext_29_8x64d', 'param_folder': 'con_False_lr_0.001_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.2441, 'avg_loss_value': 2.7033528184890745, 'avg_successful_ssim': 0.04318400819830065}, 'ground': {'top1': 0.9866}}\n",
      "Files already downloaded and verified\n",
      "resnext_29_8x64d False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_True_lr_0.00001_seed_1/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/resnext_29_8x64d/con_True_lr_0.00001_seed_1/model_best_state_c10h_val_c10_loss.pth' (epoch 30)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9695\n",
      "fgsm8   :  0.2534\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.198480324745178\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04351921099101777\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'resnext', 'model_name': 'resnext_29_8x64d', 'param_folder': 'con_True_lr_0.00001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.2534, 'avg_loss_value': 4.198480324745178, 'avg_successful_ssim': 0.04351921099101777}, 'ground': {'top1': 0.9695}}\n",
      "Files already downloaded and verified\n",
      "wrn_28_10 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/wrn_28_10/con_True_lr_0.001_seed_1/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/wrn_28_10/con_True_lr_0.001_seed_1/model_best_state_c10h_val_c10_loss.pth' (epoch 3)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9809\n",
      "fgsm8   :  0.242\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  4.123731832504273\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04382586881418207\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'wrn', 'model_name': 'wrn_28_10', 'param_folder': 'con_True_lr_0.001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.242, 'avg_loss_value': 4.123731832504273, 'avg_successful_ssim': 0.04382586881418207}, 'ground': {'top1': 0.9809}}\n",
      "Files already downloaded and verified\n",
      "wrn_28_10 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/wrn_28_10/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/wrn_28_10/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 67)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9881\n",
      "fgsm8   :  0.3531\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.164541873931885\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043436964433084646\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'wrn', 'model_name': 'wrn_28_10', 'param_folder': 'con_False_lr_0.01_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.3531, 'avg_loss_value': 2.164541873931885, 'avg_successful_ssim': 0.043436964433084646}, 'ground': {'top1': 0.9881}}\n",
      "Files already downloaded and verified\n",
      "pyramidnet_basic_110_270 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/pyramidnet_basic_110_270/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/pyramidnet_basic_110_270/con_True_lr_0.0001_seed_0/model_best_state_c10h_val_c10_loss.pth' (epoch 71)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9789\n",
      "fgsm8   :  0.2299\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  5.672549915313721\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.0431590129965602\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'pyramidnet', 'model_name': 'pyramidnet_basic_110_270', 'param_folder': 'con_True_lr_0.0001_seed_0', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'fgsm8': {'top1': 0.2299, 'avg_loss_value': 5.672549915313721, 'avg_successful_ssim': 0.0431590129965602}, 'ground': {'top1': 0.9789}}\n",
      "Files already downloaded and verified\n",
      "pyramidnet_basic_110_270 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/pyramidnet_basic_110_270/con_False_lr_0.1_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/pyramidnet_basic_110_270/con_False_lr_0.1_seed_0/model_best_state_c10h_val_loss.pth' (epoch 25)\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.9833\n",
      "fgsm8   :  0.1941\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  2.7959851121902464\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.04374538870268708\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'pyramidnet', 'model_name': 'pyramidnet_basic_110_270', 'param_folder': 'con_False_lr_0.1_seed_0', 'pth_file': 'model_best_state_c10h_val_loss.pth', 'human': True, 'fgsm8': {'top1': 0.1941, 'avg_loss_value': 2.7959851121902464, 'avg_successful_ssim': 0.04374538870268708}, 'ground': {'top1': 0.9833}}\n"
     ]
    }
   ],
   "source": [
    "n_batches = 1000 # 1 for test, 1000 for all val data (100-image batches)\n",
    "save_results = True\n",
    "break_loop = False\n",
    "\n",
    "config_folder = '/tigress/ruairidh/model_results/optimal_training_run'\n",
    "\n",
    "for mm in model_meta:\n",
    "\n",
    "    cifar_valset = cifar_loader.load_cifar_data('val', batch_size=100)\n",
    "    \n",
    "    print(mm['model_name'], mm['human'])\n",
    "    print('')\n",
    "    \n",
    "    config = parse_args(arch=mm['arch'], \n",
    "                        mdl_config=os.path.join(config_folder,\n",
    "                                                mm['model_name'],\n",
    "                                                'config.json'))\n",
    "    \n",
    "    resume_path = os.path.join(root, \n",
    "                               mm['model_name'],\n",
    "                               mm['param_folder'],\n",
    "                               mm['pth_file'])\n",
    "\n",
    "    model = load_our_model(config, resume_path)\n",
    "\n",
    "    # start attacks -----------------------------------------------------\n",
    "    adv_eval_object = adveval.AdversarialEvaluation(model, normalizer)\n",
    "\n",
    "    # we'll reuse the loss function:\n",
    "    attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "    linf_8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                     'lp_bound': 8.0 / 255.0})\n",
    "    linf_4_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                      'lp_bound': 4.0 / 255.0})\n",
    "\n",
    "\n",
    "    #------ FGSM8 Block \n",
    "    fgsm8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                     'lp_bound': 8.0/ 255.0})\n",
    "    fgsm8_attack = aa.FGSM(model, normalizer, linf_8_threat, attack_loss)\n",
    "    fgsm8_attack_kwargs = {'step_size': 0.05, \n",
    "                           'verbose': False}\n",
    "    fgsm8_attack_params = advtrain.AdversarialAttackParameters(fgsm8_attack,\n",
    "                                                               attack_specific_params=\n",
    "                                                               {'attack_kwargs': fgsm8_attack_kwargs})\n",
    "\n",
    "\n",
    "    # ------ PGD4 Block \n",
    "    pgd4_attack = aa.PGD(model, normalizer, linf_4_threat, attack_loss)\n",
    "    pgd4_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                          'num_iterations': 20, \n",
    "                          'keep_best': True,\n",
    "                          'verbose': False}\n",
    "    pgd4_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                              attack_specific_params=\n",
    "                                                              {'attack_kwargs': pgd4_attack_kwargs})\n",
    "\n",
    "    # ------ PGD4 Block \n",
    "    pgd8_attack = aa.PGD(model, normalizer, linf_8_threat, attack_loss)\n",
    "    pgd8_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                          'num_iterations': 20, \n",
    "                          'keep_best': True,\n",
    "                          'verbose': False}\n",
    "    pgd8_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                              attack_specific_params=\n",
    "                                                              {'attack_kwargs': pgd8_attack_kwargs})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    to_eval_dict = {'top1': 'top1', \n",
    "                    'avg_loss_value': 'avg_loss_value', \n",
    "                    'avg_successful_ssim': 'avg_successful_ssim'}\n",
    "\n",
    "    fgsm8_eval = adveval.EvaluationResult(fgsm8_attack_params, \n",
    "                                          to_eval=to_eval_dict)\n",
    "\n",
    "\n",
    "    pgd4_eval = adveval.EvaluationResult(pgd4_attack_params, \n",
    "                                         to_eval=to_eval_dict)\n",
    "\n",
    "    pgd8_eval = adveval.EvaluationResult(pgd8_attack_params, \n",
    "                                         to_eval=to_eval_dict)\n",
    "\n",
    "#     attack_ensemble = {'fgsm8': fgsm8_eval, \n",
    "#                        'pgd4' : pgd4_eval, \n",
    "#                        'pgd8' : pgd8_eval\n",
    "#                       }\n",
    "    attack_ensemble = {'fgsm8': fgsm8_eval}\n",
    "\n",
    "\n",
    "\n",
    "    ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, attack_ensemble, \n",
    "                                                     verbose=False, \n",
    "                                                     num_minibatches=n_batches)\n",
    "\n",
    "\n",
    "\n",
    "    sort_order = {'ground': 1, 'fgsm8': 2, 'pgd4': 3, 'pgd8': 4}\n",
    "    def pretty_printer(eval_ensemble, result_type):\n",
    "        print('~' * 10, result_type, '~' * 10)\n",
    "        for key in sorted(list(eval_ensemble.keys()), key=lambda k: sort_order[k]):\n",
    "            eval_result = eval_ensemble[key]\n",
    "            pad = 6 - len(key)\n",
    "            if result_type not in eval_result.results:\n",
    "                continue \n",
    "            avg_result = eval_result.results[result_type].avg\n",
    "            print(key, pad* ' ', ': ', avg_result)\n",
    "\n",
    "    print('')\n",
    "    pretty_printer(ensemble_out, 'top1')\n",
    "    pretty_printer(ensemble_out, 'avg_loss_value')\n",
    "    pretty_printer(ensemble_out, 'avg_successful_ssim')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    \n",
    "    for ae_key in attack_ensemble.keys():\n",
    "        for e_key in to_eval_dict.keys():\n",
    "            try:\n",
    "                mm[ae_key][e_key] = ensemble_out[ae_key].results[e_key].avg\n",
    "            except:\n",
    "                try:\n",
    "                    mm[ae_key] = {e_key: ensemble_out[ae_key].results[e_key].avg}\n",
    "                except:\n",
    "                    pass\n",
    "    print(mm)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    if break_loop: break\n",
    "    if save_results: \n",
    "        pickle.dump(model_meta, open('fgsm_results.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7959851121902464"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_out['fgsm8'].results['avg_loss_value'].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'arch': 'shake_shake',\n",
       "  'model_name': 'shake_shake_26_2x64d_SSI_cutout16',\n",
       "  'param_folder': 'con_True_lr_0.0001_seed_1',\n",
       "  'pth_file': 'model_best_state_c10h_val_c10_loss.pth',\n",
       "  'human': False,\n",
       "  'fgsm8': {'top1': 0.3945,\n",
       "   'avg_loss_value': 4.030575957298279,\n",
       "   'avg_successful_ssim': 0.0434574058042086},\n",
       "  'ground': {'top1': 0.9875}},\n",
       " {'arch': 'shake_shake',\n",
       "  'model_name': 'shake_shake_26_2x64d_SSI_cutout16',\n",
       "  'param_folder': 'con_False_lr_0.01_seed_0',\n",
       "  'pth_file': 'model_best_state_c10h_val_loss.pth',\n",
       "  'human': True,\n",
       "  'fgsm8': {'top1': 0.3854,\n",
       "   'avg_loss_value': 2.091712098121643,\n",
       "   'avg_successful_ssim': 0.043293468786753636},\n",
       "  'ground': {'top1': 0.989}}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = [mm for mm in model_meta if mm['arch']=='shake_shake']\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shake_shake_26_2x64d_SSI_cutout16 False\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_True_lr_0.0001_seed_1/model_best_state_c10h_val_c10_loss.pth' (epoch 123)\n",
      "PGD GRAD UPDATE 1\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.98\n",
      "pgd4    :  0.98\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  0.03144082546234131\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 2\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuacp/anaconda3/lib/python3.6/site-packages/skimage/util/arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  1.0\n",
      "pgd4    :  0.7\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  1.427823805809021\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.000668124217690765\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 3\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.97\n",
      "pgd4    :  0.32\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  5.750855340957641\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.0017781359293342818\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 4\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  1.0\n",
      "pgd4    :  0.14\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  10.125313777923584\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.003198474210366652\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 5\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.99\n",
      "pgd4    :  0.03\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  14.931519737243653\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.004635109303991808\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 6\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.99\n",
      "pgd4    :  0.01\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  16.54852264404297\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.00521653965053436\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 7\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.99\n",
      "pgd4    :  0.0\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  17.480526905059815\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.005618594892833934\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 8\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.98\n",
      "pgd4    :  0.02\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  20.383681411743165\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.005459731206000993\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 9\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.98\n",
      "pgd4    :  0.01\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  21.985039234161377\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.006187770642590182\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 10\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.98\n",
      "pgd4    :  0.02\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  22.361364154815675\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.0069376103329004644\n",
      "\n",
      "\n",
      "\n",
      "{'arch': 'shake_shake', 'model_name': 'shake_shake_26_2x64d_SSI_cutout16', 'param_folder': 'con_True_lr_0.0001_seed_1', 'pth_file': 'model_best_state_c10h_val_c10_loss.pth', 'human': False, 'pgd4': {'top1': [0.98, 0.7, 0.32, 0.14, 0.03, 0.01, 0.0, 0.02, 0.01, 0.02], 'avg_loss_value': [0.03144082546234131, 1.427823805809021, 5.750855340957641, 10.125313777923584, 14.931519737243653, 16.54852264404297, 17.480526905059815, 20.383681411743165, 21.985039234161377, 22.361364154815675], 'avg_successful_ssim': [0, 0.000668124217690765, 0.0017781359293342818, 0.003198474210366652, 0.004635109303991808, 0.00521653965053436, 0.005618594892833934, 0.005459731206000993, 0.006187770642590182, 0.0069376103329004644]}, 'ground': {'top1': [0.98, 1.0, 0.97, 1.0, 0.99, 0.99, 0.99, 0.98, 0.98, 0.98]}}\n",
      "shake_shake_26_2x64d_SSI_cutout16 True\n",
      "\n",
      "=> loading checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth'\n",
      "=> loaded checkpoint '/tigress/joshuacp/model_results/optimal_basic_tuning_josh_alt_controls/shake_shake_26_2x64d_SSI_cutout16/con_False_lr_0.01_seed_0/model_best_state_c10h_val_loss.pth' (epoch 69)\n",
      "PGD GRAD UPDATE 1\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.98\n",
      "pgd4    :  0.98\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  0.07033957004547119\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 2\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.99\n",
      "pgd4    :  0.87\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  0.4335375380516052\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.0011538665535912134\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 3\n",
      "Files already downloaded and verified\n",
      "\n",
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.99\n",
      "pgd4    :  0.4\n",
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "pgd4    :  2.2285641741752626\n",
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "pgd4    :  0.0017995788778028608\n",
      "\n",
      "\n",
      "\n",
      "PGD GRAD UPDATE 4\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# PGM ATTACKS ONLY!!!\n",
    "\n",
    "# model_meta = get_meta(filt='shake_shake')\n",
    "model_meta = get_meta()\n",
    "\n",
    "n_batches = 50\n",
    "save_results = True\n",
    "break_loop = False\n",
    "\n",
    "config_folder = '/tigress/ruairidh/model_results/optimal_training_run'\n",
    "\n",
    "for mm in model_meta:\n",
    "    \n",
    "    print(mm['model_name'], mm['human'])\n",
    "    print('')\n",
    "    \n",
    "    config = parse_args(arch=mm['arch'], \n",
    "                        mdl_config=os.path.join(config_folder,\n",
    "                                                mm['model_name'],\n",
    "                                                'config.json'))\n",
    "    \n",
    "    resume_path = os.path.join(root, \n",
    "                               mm['model_name'],\n",
    "                               mm['param_folder'],\n",
    "                               mm['pth_file'])\n",
    "\n",
    "    model = load_our_model(config, resume_path)\n",
    "    \n",
    "    for n_updates in range(10):\n",
    "        print('PGD GRAD UPDATE', n_updates+1)\n",
    "        cifar_valset = cifar_loader.load_cifar_data('val', batch_size=2)\n",
    "\n",
    "        # start attacks -----------------------------------------------------\n",
    "        adv_eval_object = adveval.AdversarialEvaluation(model, normalizer)\n",
    "\n",
    "        # we'll reuse the loss function:\n",
    "        attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "        linf_8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                         'lp_bound': 8.0 / 255.0})\n",
    "        linf_4_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                          'lp_bound': 4.0 / 255.0})\n",
    "\n",
    "\n",
    "        #------ FGSM8 Block \n",
    "        fgsm8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                         'lp_bound': 8.0/ 255.0})\n",
    "        fgsm8_attack = aa.FGSM(model, normalizer, linf_8_threat, attack_loss)\n",
    "        fgsm8_attack_kwargs = {'step_size': 0.05, \n",
    "                               'verbose': False}\n",
    "        fgsm8_attack_params = advtrain.AdversarialAttackParameters(fgsm8_attack,\n",
    "                                                                   attack_specific_params=\n",
    "                                                                   {'attack_kwargs': fgsm8_attack_kwargs})\n",
    "\n",
    "\n",
    "        # ------ PGD4 Block \n",
    "        pgd4_attack = aa.PGD(model, normalizer, linf_4_threat, attack_loss)\n",
    "        pgd4_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                              'num_iterations': n_updates, \n",
    "                              'keep_best': True,\n",
    "                              'verbose': False}\n",
    "        pgd4_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                                  attack_specific_params=\n",
    "                                                                  {'attack_kwargs': pgd4_attack_kwargs})\n",
    "\n",
    "        # ------ PGD4 Block \n",
    "        pgd8_attack = aa.PGD(model, normalizer, linf_8_threat, attack_loss)\n",
    "        pgd8_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                              'num_iterations': n_updates, \n",
    "                              'keep_best': True,\n",
    "                              'verbose': False}\n",
    "        pgd8_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                                  attack_specific_params=\n",
    "                                                                  {'attack_kwargs': pgd8_attack_kwargs})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        to_eval_dict = {'top1': 'top1', \n",
    "                        'avg_loss_value': 'avg_loss_value', \n",
    "                        'avg_successful_ssim': 'avg_successful_ssim'}\n",
    "\n",
    "        fgsm8_eval = adveval.EvaluationResult(fgsm8_attack_params, \n",
    "                                              to_eval=to_eval_dict)\n",
    "\n",
    "\n",
    "        pgd4_eval = adveval.EvaluationResult(pgd4_attack_params, \n",
    "                                             to_eval=to_eval_dict)\n",
    "\n",
    "        pgd8_eval = adveval.EvaluationResult(pgd8_attack_params, \n",
    "                                             to_eval=to_eval_dict)\n",
    "\n",
    "        attack_ensemble = {\n",
    "                           'pgd4' : pgd4_eval, \n",
    "#                            'pgd8' : pgd8_eval\n",
    "                          }\n",
    "\n",
    "\n",
    "\n",
    "        ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, attack_ensemble, \n",
    "                                                         verbose=False, \n",
    "                                                         num_minibatches=n_batches)\n",
    "\n",
    "\n",
    "\n",
    "        sort_order = {'ground': 1, 'fgsm8': 2, 'pgd4': 3, 'pgd8': 4}\n",
    "        def pretty_printer(eval_ensemble, result_type):\n",
    "            print('~' * 10, result_type, '~' * 10)\n",
    "            for key in sorted(list(eval_ensemble.keys()), key=lambda k: sort_order[k]):\n",
    "                eval_result = eval_ensemble[key]\n",
    "                pad = 6 - len(key)\n",
    "                if result_type not in eval_result.results:\n",
    "                    continue \n",
    "                avg_result = eval_result.results[result_type].avg\n",
    "                print(key, pad* ' ', ': ', avg_result)\n",
    "\n",
    "        print('')\n",
    "        pretty_printer(ensemble_out, 'top1')\n",
    "        pretty_printer(ensemble_out, 'avg_loss_value')\n",
    "        pretty_printer(ensemble_out, 'avg_successful_ssim')\n",
    "        print('')\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        for ae_key in attack_ensemble.keys():\n",
    "            if ae_key not in mm.keys():\n",
    "                mm[ae_key] = {}\n",
    "            for e_key in to_eval_dict.keys():\n",
    "                if e_key not in mm[ae_key].keys() and (e_key in ensemble_out[ae_key].results.keys()):\n",
    "                    mm[ae_key][e_key] = []\n",
    "                try:\n",
    "                    mm[ae_key][e_key].append(ensemble_out[ae_key].results[e_key].avg)\n",
    "                except:\n",
    "                    pass\n",
    "#         print(mm)\n",
    "\n",
    "#         del model\n",
    "        gc.collect()\n",
    "        if break_loop: break\n",
    "        if save_results: \n",
    "            pickle.dump(model_meta, open('pgd_results.pickle','wb'))\n",
    "    print(mm)\n",
    "    if break_loop: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>ground</th>\n",
       "      <th>human</th>\n",
       "      <th>model_name</th>\n",
       "      <th>param_folder</th>\n",
       "      <th>pgd4</th>\n",
       "      <th>pth_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shake_shake</td>\n",
       "      <td>{'top1': [0.98, 0.99, 0.99, 1.0, 0.98, 1.0, 1....</td>\n",
       "      <td>False</td>\n",
       "      <td>shake_shake_26_2x64d_SSI_cutout16</td>\n",
       "      <td>con_True_lr_0.0001_seed_1</td>\n",
       "      <td>{'top1': [0.98, 0.69, 0.32, 0.12, 0.03, 0.03, ...</td>\n",
       "      <td>model_best_state_c10h_val_c10_loss.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shake_shake</td>\n",
       "      <td>{'top1': [0.98, 1.0, 0.97, 0.97, 0.98, 1.0, 0....</td>\n",
       "      <td>True</td>\n",
       "      <td>shake_shake_26_2x64d_SSI_cutout16</td>\n",
       "      <td>con_False_lr_0.01_seed_0</td>\n",
       "      <td>{'top1': [0.98, 0.86, 0.53, 0.22, 0.1, 0.05, 0...</td>\n",
       "      <td>model_best_state_c10h_val_loss.pth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          arch                                             ground  human  \\\n",
       "0  shake_shake  {'top1': [0.98, 0.99, 0.99, 1.0, 0.98, 1.0, 1....  False   \n",
       "1  shake_shake  {'top1': [0.98, 1.0, 0.97, 0.97, 0.98, 1.0, 0....   True   \n",
       "\n",
       "                          model_name               param_folder  \\\n",
       "0  shake_shake_26_2x64d_SSI_cutout16  con_True_lr_0.0001_seed_1   \n",
       "1  shake_shake_26_2x64d_SSI_cutout16   con_False_lr_0.01_seed_0   \n",
       "\n",
       "                                                pgd4  \\\n",
       "0  {'top1': [0.98, 0.69, 0.32, 0.12, 0.03, 0.03, ...   \n",
       "1  {'top1': [0.98, 0.86, 0.53, 0.22, 0.1, 0.05, 0...   \n",
       "\n",
       "                                 pth_file  \n",
       "0  model_best_state_c10h_val_c10_loss.pth  \n",
       "1      model_best_state_c10h_val_loss.pth  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot_all = pd.DataFrame(model_meta)\n",
    "df_plot_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for mn in df_plot_all.model_name.unique():\n",
    "    \n",
    "    df_plot = df_plot_all[df_plot_all.model_name==mn].copy()\n",
    "    \n",
    "    y = df_plot[df_plot.human==True]['pgd4'].values[0]['avg_loss_value']\n",
    "    x = np.arange(len(y))\n",
    "    plt.plot(x, y)\n",
    "\n",
    "    y = df_plot[df_plot.human==False]['pgd4'].values[0]['avg_loss_value']\n",
    "    x = np.arange(len(y))\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we'll be looking at the techniques we'll use to evaluate both attacks and defenses. In general, the task we want to solve is this: we have a classifier trained on a dataset and wish to evaluate its accuracy against unperturbed inputs as well as various properties of an adversarial attack that has gradient access to this classifier. \n",
    "\n",
    "Recall that an adversarial attack here has many degrees of freedom we can choose:\n",
    "- Threat model: $\\ell_p$-bounded noise, rotations, translations, flow, any combination of the above\n",
    "- Bounds for the threat model\n",
    "- Attack technique: PGD, FGSM, Carlini-Wagner\n",
    "- Attack parameters: number of iterations, step size, loss functions, etc\n",
    "\n",
    "And we can choose to evaluate several properties of each attack on a network: \n",
    "- Top-k accuracy \n",
    "- Average successful loss value \n",
    "- The generated adversarial images \n",
    "- Average distance (say according to a custom function) of generated adversarial images to their originals\n",
    "\n",
    "All we'll be doing in this file is walking through an example of how to build objects to perform evaluations of (some of) these properties on a medley of attacks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an AdversarialEvaluationObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/adversarial_evaluation.png\",width=60,height=60>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"images/adversarial_evaluation.png\",width=60,height=60>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image describes the general workflow: \n",
    "First we initialize an `AdversarialEvaluation` instance which keeps track of which classifier we're evaluating against, as well as the normalizer (which recall just performs some operations on raw-data to make it classifier-friendly). This instance will have an `evaluate_ensemble` method which needs as arguments a DataLoader and a dictionary, called the `attack_ensemble`, that contains the attacks (which are wrapped up in `EvaluationResult` instances). This method will output a dictionary that points to the same `EvaluationResult` objects which now have the result data stored in them. Unless otherwise specified, we'll also evaluate the ground accuracy of the classifier and include that in the return-value as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and build up everything except the `EvaluationResult` objects and proceed from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model and normalizer\n",
    "# model, normalizer = cifar_loader.load_pretrained_cifar_resnet(flavor=20, return_normalizer=True) \n",
    "\n",
    "# Load the evaluation dataset \n",
    "cifar_valset = cifar_loader.load_cifar_data('val') \n",
    "\n",
    "# Put this into the AdversarialEvaluation object\n",
    "adv_eval_object = adveval.AdversarialEvaluation(model, normalizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Attack Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall in tutorial_1 we built `AdversarialAttack` objects and used their `.attack(...)` methods to generate adversarial perturbations, where the keyword arguments to `.attack(...)` described the parameters of the attack.\n",
    "\n",
    "And then in tutorial_2 we build `AdversarialAttackParameters` objects which is a wrapper to hold an `AdversarialAttack` object and the kwargs that described the parameters of the attack. We used this to generate attacks inside the training loop to perform adversarial training.\n",
    "\n",
    "And finally, in this tutorial we'll build `EvaluationResult` objects which hold an `AdversarialAttackParameters` object and a dictionary storing some information about what we'll evaluate.\n",
    "\n",
    "The following image summarizes the data structures we've built (the bullet points refer to the arguments needed upon construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/evaluationResult_ds.png\",width=60,height=60>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html \n",
    "<img src=\"images/evaluationResult_ds.png\",width=60,height=60>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worked example, we'll build 3 different evaluation results and evaluate them simultaneously:\n",
    "- **FGSM8**: An additive noise attack, with $\\ell_\\infty$ bound of 8.0, attacked using FGSM \n",
    "- **PGD4**: An additive noise attack, with $\\ell_\\infty$ bound of 4.0, attacked using PGD \n",
    "- **PGD8**: An additive noise attack, with $\\ell_\\infty$ bound of 8.0, attacked using PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's build the attack parameters for each.\n",
    "# Note: we're not doing anything new yet. These constructions are covered in the first two tutorials\n",
    "\n",
    "# we'll reuse the loss function:\n",
    "attack_loss = plf.VanillaXentropy(model, normalizer)\n",
    "linf_8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                 'lp_bound': 8.0 / 255.0})\n",
    "linf_4_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                  'lp_bound': 4.0 / 255.0})\n",
    "\n",
    "\n",
    "#------ FGSM8 Block \n",
    "fgsm8_threat = ap.ThreatModel(ap.DeltaAddition, {'lp_style': 'inf', \n",
    "                                                 'lp_bound': 8.0/ 255.0})\n",
    "fgsm8_attack = aa.FGSM(model, normalizer, linf_8_threat, attack_loss)\n",
    "fgsm8_attack_kwargs = {'step_size': 0.05, \n",
    "                       'verbose': False}\n",
    "fgsm8_attack_params = advtrain.AdversarialAttackParameters(fgsm8_attack,\n",
    "                                                           attack_specific_params=\n",
    "                                                           {'attack_kwargs': fgsm8_attack_kwargs})\n",
    "\n",
    "\n",
    "# ------ PGD4 Block \n",
    "pgd4_attack = aa.PGD(model, normalizer, linf_4_threat, attack_loss)\n",
    "pgd4_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                      'num_iterations': 20, \n",
    "                      'keep_best': True,\n",
    "                      'verbose': False}\n",
    "pgd4_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                          attack_specific_params=\n",
    "                                                          {'attack_kwargs': pgd4_attack_kwargs})\n",
    "\n",
    "# ------ PGD4 Block \n",
    "pgd8_attack = aa.PGD(model, normalizer, linf_8_threat, attack_loss)\n",
    "pgd8_attack_kwargs = {'step_size': 1.0 / 255.0, \n",
    "                      'num_iterations': 20, \n",
    "                      'keep_best': True,\n",
    "                      'verbose': False}\n",
    "pgd8_attack_params = advtrain.AdversarialAttackParameters(pgd4_attack, \n",
    "                                                          attack_specific_params=\n",
    "                                                          {'attack_kwargs': pgd8_attack_kwargs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Next we'll build the EvaluationResult objects that wrap these. \n",
    "And let's say we'll evaluate the:\n",
    "- top1 accuracy \n",
    "- average loss \n",
    "- average SSIM distance of successful perturbations [don't worry too much about this]\n",
    "\n",
    "The 'to_eval' dict as passed in the constructor has structure \n",
    " {key : <shorthand fxn>}\n",
    "where key is just a human-readable handle for what's being evaluated\n",
    "and shorthand_fxn is either a string for prebuilt evaluators, or you can pass in a general function to evaluate\n",
    "'''\n",
    "\n",
    "to_eval_dict = {'top1': 'top1', \n",
    "                'avg_loss_value': 'avg_loss_value', \n",
    "                'avg_successful_ssim': 'avg_successful_ssim'}\n",
    "\n",
    "fgsm8_eval = adveval.EvaluationResult(fgsm8_attack_params, \n",
    "                                      to_eval=to_eval_dict)\n",
    "\n",
    "\n",
    "pgd4_eval = adveval.EvaluationResult(pgd4_attack_params, \n",
    "                                     to_eval=to_eval_dict)\n",
    "\n",
    "pgd8_eval = adveval.EvaluationResult(pgd8_attack_params, \n",
    "                                     to_eval=to_eval_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our `EvaluationResult` objects built, all that remains is to collect all these into a dictionary and pass them to our `AdversarialEvaluation` object and interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting minibatch 0...\n",
      "\t (mb: 0) evaluating fgsm8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshuacp/anaconda3/lib/python3.6/site-packages/skimage/util/arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (mb: 0) evaluating pgd4...\n",
      "\t (mb: 0) evaluating pgd8...\n",
      "\t (mb: 0) evaluating ground...\n"
     ]
    }
   ],
   "source": [
    "attack_ensemble = {'fgsm8': fgsm8_eval, \n",
    "                   'pgd4' : pgd4_eval, \n",
    "                   'pgd8' : pgd8_eval\n",
    "                  }\n",
    "ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, attack_ensemble, \n",
    "                                                 verbose=True, \n",
    "                                                 num_minibatches=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the evaluation results. First notice that the key `'ground'` has been added to the ensemble output. This stores the top1 accuracy of unperturbed inputs (and thus the accuracy of the classifier).\n",
    "\n",
    "In general, the results of the evaluations will be stored in the `EvaluationResult.results` dictionary, with the keys being the same as the evaluation types desired. These generally will point to an `AverageMeter` object, which is a simple little object to keep track of average values. You can query its `.avg` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fgsm8', 'pgd4', 'pgd8', 'ground'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'top1': <utils.pytorch_utils.AverageMeter at 0x7fe8d4075160>,\n",
       " 'avg_loss_value': <utils.pytorch_utils.AverageMeter at 0x7fe8d40750f0>,\n",
       " 'avg_successful_ssim': <utils.pytorch_utils.AverageMeter at 0x7fe8d4075208>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First notice the keys of ensemble_out include ground:\n",
    "print(attack_ensemble.keys())\n",
    "\n",
    "attack_ensemble['pgd8'].results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's build a little helper to print things out cleanly:\n",
    "\n",
    "sort_order = {'ground': 1, 'fgsm8': 2, 'pgd4': 3, 'pgd8': 4}\n",
    "def pretty_printer(eval_ensemble, result_type):\n",
    "    print('~' * 10, result_type, '~' * 10)\n",
    "    for key in sorted(list(eval_ensemble.keys()), key=lambda k: sort_order[k]):\n",
    "        eval_result = eval_ensemble[key]\n",
    "        pad = 6 - len(key)\n",
    "        if result_type not in eval_result.results:\n",
    "            continue \n",
    "        avg_result = eval_result.results[result_type].avg\n",
    "        print(key, pad* ' ', ': ', avg_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ top1 ~~~~~~~~~~\n",
      "ground  :  0.921875\n",
      "fgsm8   :  0.15625\n",
      "pgd4    :  0.0\n",
      "pgd8    :  0.0\n"
     ]
    }
   ],
   "source": [
    "'''And then we can print out and look at the results:\n",
    "This prints the accuracy. \n",
    "Ground is the unperturbed accuracy. \n",
    "If everything is done right, we should see that PGD with an l_inf bound of 4 is a stronger attack \n",
    "against undefended networks than FGSM with an l_inf bound of 8\n",
    "'''\n",
    "pretty_printer(ensemble_out, 'top1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ avg_loss_value ~~~~~~~~~~\n",
      "fgsm8   :  6.651584625244141\n",
      "pgd4    :  28.52568817138672\n",
      "pgd8    :  28.52568817138672\n"
     ]
    }
   ],
   "source": [
    "# We can examine the loss (noting that we seek to 'maximize' loss in the adversarial example domain)\n",
    "pretty_printer(ensemble_out, 'avg_loss_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ avg_successful_ssim ~~~~~~~~~~\n",
      "fgsm8   :  0.043479578028236654\n",
      "pgd4    :  0.008117672481531168\n",
      "pgd8    :  0.008117672481531168\n"
     ]
    }
   ],
   "source": [
    "# This is actually 1-SSIM, which can serve as a makeshift 'similarity index', \n",
    "# which essentially gives a meterstick for how similar the perturbed images are to the originals\n",
    "pretty_printer(ensemble_out, 'avg_successful_ssim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Advanced): Custom Evaluation Techniques\n",
    "For most use cases, the predefined evalutions (accuracy, loss, etc) should be fine. Should one want to extend this, however, it's not too hard to do. We'll walk through an example where we evaluate the average l_inf distance of **successful** attacks. \n",
    "\n",
    "First we'll need to build a function that takes in an `EvaluationResult` object, a label and the tuple that is generated from the output of `AdversarialAttackParameters.attack(...)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_successful_linf(self, eval_label, attack_out):\n",
    "    \n",
    "    # First set up the averageMeter to hold these results\n",
    "    if self.results[eval_label] is None:\n",
    "        self.results[eval_label] = utils.AverageMeter() \n",
    "    result = self.results[eval_label]\n",
    "    \n",
    "    # Collect the successful attacks only: \n",
    "    successful_pert, successful_orig = self._get_successful_attacks(attack_out)\n",
    "    \n",
    "    # Handle the degenerate case \n",
    "    if successful_pert is None or successful_pert.numel() == 0:\n",
    "        return \n",
    "    \n",
    "    # Compute the l_inf dist per example\n",
    "    batched_norms = utils.batchwise_norm(torch.abs(successful_pert - successful_orig), \n",
    "                                         'inf', dim=0)\n",
    "    # Update the result (and multiply by 255 for ease in exposition)\n",
    "    batch_avg = float(torch.sum(batched_norms)) / successful_pert.shape[0]\n",
    "    \n",
    "    result.update(batch_avg * 255, n=successful_pert.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting minibatch 0...\n",
      "\t (mb: 0) evaluating fgsm8...\n",
      "\t (mb: 0) evaluating pgd4...\n",
      "\t (mb: 0) evaluating pgd8...\n",
      "\t (mb: 0) evaluating ground...\n",
      "Starting minibatch 1...\n",
      "\t (mb: 1) evaluating fgsm8...\n",
      "\t (mb: 1) evaluating pgd4...\n",
      "\t (mb: 1) evaluating pgd8...\n",
      "\t (mb: 1) evaluating ground...\n",
      "Starting minibatch 2...\n",
      "\t (mb: 2) evaluating fgsm8...\n",
      "\t (mb: 2) evaluating pgd4...\n",
      "\t (mb: 2) evaluating pgd8...\n",
      "\t (mb: 2) evaluating ground...\n",
      "Starting minibatch 3...\n",
      "\t (mb: 3) evaluating fgsm8...\n",
      "\t (mb: 3) evaluating pgd4...\n",
      "\t (mb: 3) evaluating pgd8...\n",
      "\t (mb: 3) evaluating ground...\n",
      "Starting minibatch 4...\n",
      "\t (mb: 4) evaluating fgsm8...\n",
      "\t (mb: 4) evaluating pgd4...\n",
      "\t (mb: 4) evaluating pgd8...\n",
      "\t (mb: 4) evaluating ground...\n",
      "Starting minibatch 5...\n",
      "\t (mb: 5) evaluating fgsm8...\n",
      "\t (mb: 5) evaluating pgd4...\n",
      "\t (mb: 5) evaluating pgd8...\n",
      "\t (mb: 5) evaluating ground...\n",
      "Starting minibatch 6...\n",
      "\t (mb: 6) evaluating fgsm8...\n",
      "\t (mb: 6) evaluating pgd4...\n",
      "\t (mb: 6) evaluating pgd8...\n",
      "\t (mb: 6) evaluating ground...\n",
      "Starting minibatch 7...\n",
      "\t (mb: 7) evaluating fgsm8...\n",
      "\t (mb: 7) evaluating pgd4...\n",
      "\t (mb: 7) evaluating pgd8...\n",
      "\t (mb: 7) evaluating ground...\n",
      "Starting minibatch 8...\n",
      "\t (mb: 8) evaluating fgsm8...\n",
      "\t (mb: 8) evaluating pgd4...\n",
      "\t (mb: 8) evaluating pgd8...\n",
      "\t (mb: 8) evaluating ground...\n",
      "Starting minibatch 9...\n",
      "\t (mb: 9) evaluating fgsm8...\n",
      "\t (mb: 9) evaluating pgd4...\n",
      "\t (mb: 9) evaluating pgd8...\n",
      "\t (mb: 9) evaluating ground...\n",
      "Starting minibatch 10...\n",
      "\t (mb: 10) evaluating fgsm8...\n",
      "\t (mb: 10) evaluating pgd4...\n",
      "\t (mb: 10) evaluating pgd8...\n",
      "\t (mb: 10) evaluating ground...\n",
      "Starting minibatch 11...\n",
      "\t (mb: 11) evaluating fgsm8...\n",
      "\t (mb: 11) evaluating pgd4...\n",
      "\t (mb: 11) evaluating pgd8...\n",
      "\t (mb: 11) evaluating ground...\n",
      "Starting minibatch 12...\n",
      "\t (mb: 12) evaluating fgsm8...\n",
      "\t (mb: 12) evaluating pgd4...\n",
      "\t (mb: 12) evaluating pgd8...\n",
      "\t (mb: 12) evaluating ground...\n",
      "Starting minibatch 13...\n",
      "\t (mb: 13) evaluating fgsm8...\n",
      "\t (mb: 13) evaluating pgd4...\n",
      "\t (mb: 13) evaluating pgd8...\n",
      "\t (mb: 13) evaluating ground...\n",
      "Starting minibatch 14...\n",
      "\t (mb: 14) evaluating fgsm8...\n",
      "\t (mb: 14) evaluating pgd4...\n",
      "\t (mb: 14) evaluating pgd8...\n",
      "\t (mb: 14) evaluating ground...\n",
      "Starting minibatch 15...\n",
      "\t (mb: 15) evaluating fgsm8...\n",
      "\t (mb: 15) evaluating pgd4...\n",
      "\t (mb: 15) evaluating pgd8...\n",
      "\t (mb: 15) evaluating ground...\n",
      "Starting minibatch 16...\n",
      "\t (mb: 16) evaluating fgsm8...\n",
      "\t (mb: 16) evaluating pgd4...\n",
      "\t (mb: 16) evaluating pgd8...\n",
      "\t (mb: 16) evaluating ground...\n",
      "Starting minibatch 17...\n",
      "\t (mb: 17) evaluating fgsm8...\n",
      "\t (mb: 17) evaluating pgd4...\n",
      "\t (mb: 17) evaluating pgd8...\n",
      "\t (mb: 17) evaluating ground...\n",
      "Starting minibatch 18...\n",
      "\t (mb: 18) evaluating fgsm8...\n",
      "\t (mb: 18) evaluating pgd4...\n",
      "\t (mb: 18) evaluating pgd8...\n",
      "\t (mb: 18) evaluating ground...\n",
      "Starting minibatch 19...\n",
      "\t (mb: 19) evaluating fgsm8...\n",
      "\t (mb: 19) evaluating pgd4...\n",
      "\t (mb: 19) evaluating pgd8...\n",
      "\t (mb: 19) evaluating ground...\n",
      "Starting minibatch 20...\n",
      "\t (mb: 20) evaluating fgsm8...\n",
      "\t (mb: 20) evaluating pgd4...\n",
      "\t (mb: 20) evaluating pgd8...\n",
      "\t (mb: 20) evaluating ground...\n",
      "Starting minibatch 21...\n",
      "\t (mb: 21) evaluating fgsm8...\n",
      "\t (mb: 21) evaluating pgd4...\n",
      "\t (mb: 21) evaluating pgd8...\n",
      "\t (mb: 21) evaluating ground...\n",
      "Starting minibatch 22...\n",
      "\t (mb: 22) evaluating fgsm8...\n",
      "\t (mb: 22) evaluating pgd4...\n",
      "\t (mb: 22) evaluating pgd8...\n",
      "\t (mb: 22) evaluating ground...\n",
      "Starting minibatch 23...\n",
      "\t (mb: 23) evaluating fgsm8...\n",
      "\t (mb: 23) evaluating pgd4...\n",
      "\t (mb: 23) evaluating pgd8...\n",
      "\t (mb: 23) evaluating ground...\n",
      "Starting minibatch 24...\n",
      "\t (mb: 24) evaluating fgsm8...\n",
      "\t (mb: 24) evaluating pgd4...\n",
      "\t (mb: 24) evaluating pgd8...\n",
      "\t (mb: 24) evaluating ground...\n",
      "Starting minibatch 25...\n",
      "\t (mb: 25) evaluating fgsm8...\n",
      "\t (mb: 25) evaluating pgd4...\n",
      "\t (mb: 25) evaluating pgd8...\n",
      "\t (mb: 25) evaluating ground...\n",
      "Starting minibatch 26...\n",
      "\t (mb: 26) evaluating fgsm8...\n",
      "\t (mb: 26) evaluating pgd4...\n",
      "\t (mb: 26) evaluating pgd8...\n",
      "\t (mb: 26) evaluating ground...\n",
      "Starting minibatch 27...\n",
      "\t (mb: 27) evaluating fgsm8...\n",
      "\t (mb: 27) evaluating pgd4...\n",
      "\t (mb: 27) evaluating pgd8...\n",
      "\t (mb: 27) evaluating ground...\n",
      "Starting minibatch 28...\n",
      "\t (mb: 28) evaluating fgsm8...\n",
      "\t (mb: 28) evaluating pgd4...\n",
      "\t (mb: 28) evaluating pgd8...\n",
      "\t (mb: 28) evaluating ground...\n",
      "Starting minibatch 29...\n",
      "\t (mb: 29) evaluating fgsm8...\n",
      "\t (mb: 29) evaluating pgd4...\n",
      "\t (mb: 29) evaluating pgd8...\n",
      "\t (mb: 29) evaluating ground...\n",
      "Starting minibatch 30...\n",
      "\t (mb: 30) evaluating fgsm8...\n",
      "\t (mb: 30) evaluating pgd4...\n",
      "\t (mb: 30) evaluating pgd8...\n",
      "\t (mb: 30) evaluating ground...\n",
      "Starting minibatch 31...\n",
      "\t (mb: 31) evaluating fgsm8...\n",
      "\t (mb: 31) evaluating pgd4...\n",
      "\t (mb: 31) evaluating pgd8...\n",
      "\t (mb: 31) evaluating ground...\n",
      "Starting minibatch 32...\n",
      "\t (mb: 32) evaluating fgsm8...\n",
      "\t (mb: 32) evaluating pgd4...\n",
      "\t (mb: 32) evaluating pgd8...\n",
      "\t (mb: 32) evaluating ground...\n",
      "Starting minibatch 33...\n",
      "\t (mb: 33) evaluating fgsm8...\n",
      "\t (mb: 33) evaluating pgd4...\n",
      "\t (mb: 33) evaluating pgd8...\n",
      "\t (mb: 33) evaluating ground...\n",
      "Starting minibatch 34...\n",
      "\t (mb: 34) evaluating fgsm8...\n",
      "\t (mb: 34) evaluating pgd4...\n",
      "\t (mb: 34) evaluating pgd8...\n",
      "\t (mb: 34) evaluating ground...\n",
      "Starting minibatch 35...\n",
      "\t (mb: 35) evaluating fgsm8...\n",
      "\t (mb: 35) evaluating pgd4...\n",
      "\t (mb: 35) evaluating pgd8...\n",
      "\t (mb: 35) evaluating ground...\n",
      "Starting minibatch 36...\n",
      "\t (mb: 36) evaluating fgsm8...\n",
      "\t (mb: 36) evaluating pgd4...\n",
      "\t (mb: 36) evaluating pgd8...\n",
      "\t (mb: 36) evaluating ground...\n",
      "Starting minibatch 37...\n",
      "\t (mb: 37) evaluating fgsm8...\n",
      "\t (mb: 37) evaluating pgd4...\n",
      "\t (mb: 37) evaluating pgd8...\n",
      "\t (mb: 37) evaluating ground...\n",
      "Starting minibatch 38...\n",
      "\t (mb: 38) evaluating fgsm8...\n",
      "\t (mb: 38) evaluating pgd4...\n",
      "\t (mb: 38) evaluating pgd8...\n",
      "\t (mb: 38) evaluating ground...\n",
      "Starting minibatch 39...\n",
      "\t (mb: 39) evaluating fgsm8...\n",
      "\t (mb: 39) evaluating pgd4...\n",
      "\t (mb: 39) evaluating pgd8...\n",
      "\t (mb: 39) evaluating ground...\n",
      "Starting minibatch 40...\n",
      "\t (mb: 40) evaluating fgsm8...\n",
      "\t (mb: 40) evaluating pgd4...\n",
      "\t (mb: 40) evaluating pgd8...\n",
      "\t (mb: 40) evaluating ground...\n",
      "Starting minibatch 41...\n",
      "\t (mb: 41) evaluating fgsm8...\n",
      "\t (mb: 41) evaluating pgd4...\n",
      "\t (mb: 41) evaluating pgd8...\n",
      "\t (mb: 41) evaluating ground...\n",
      "Starting minibatch 42...\n",
      "\t (mb: 42) evaluating fgsm8...\n",
      "\t (mb: 42) evaluating pgd4...\n",
      "\t (mb: 42) evaluating pgd8...\n",
      "\t (mb: 42) evaluating ground...\n",
      "Starting minibatch 43...\n",
      "\t (mb: 43) evaluating fgsm8...\n",
      "\t (mb: 43) evaluating pgd4...\n",
      "\t (mb: 43) evaluating pgd8...\n",
      "\t (mb: 43) evaluating ground...\n",
      "Starting minibatch 44...\n",
      "\t (mb: 44) evaluating fgsm8...\n",
      "\t (mb: 44) evaluating pgd4...\n",
      "\t (mb: 44) evaluating pgd8...\n",
      "\t (mb: 44) evaluating ground...\n",
      "Starting minibatch 45...\n",
      "\t (mb: 45) evaluating fgsm8...\n",
      "\t (mb: 45) evaluating pgd4...\n",
      "\t (mb: 45) evaluating pgd8...\n",
      "\t (mb: 45) evaluating ground...\n",
      "Starting minibatch 46...\n",
      "\t (mb: 46) evaluating fgsm8...\n",
      "\t (mb: 46) evaluating pgd4...\n",
      "\t (mb: 46) evaluating pgd8...\n",
      "\t (mb: 46) evaluating ground...\n",
      "Starting minibatch 47...\n",
      "\t (mb: 47) evaluating fgsm8...\n",
      "\t (mb: 47) evaluating pgd4...\n",
      "\t (mb: 47) evaluating pgd8...\n",
      "\t (mb: 47) evaluating ground...\n",
      "Starting minibatch 48...\n",
      "\t (mb: 48) evaluating fgsm8...\n",
      "\t (mb: 48) evaluating pgd4...\n",
      "\t (mb: 48) evaluating pgd8...\n",
      "\t (mb: 48) evaluating ground...\n",
      "Starting minibatch 49...\n",
      "\t (mb: 49) evaluating fgsm8...\n",
      "\t (mb: 49) evaluating pgd4...\n",
      "\t (mb: 49) evaluating pgd8...\n",
      "\t (mb: 49) evaluating ground...\n",
      "Starting minibatch 50...\n",
      "\t (mb: 50) evaluating fgsm8...\n",
      "\t (mb: 50) evaluating pgd4...\n",
      "\t (mb: 50) evaluating pgd8...\n",
      "\t (mb: 50) evaluating ground...\n",
      "Starting minibatch 51...\n",
      "\t (mb: 51) evaluating fgsm8...\n",
      "\t (mb: 51) evaluating pgd4...\n",
      "\t (mb: 51) evaluating pgd8...\n",
      "\t (mb: 51) evaluating ground...\n",
      "Starting minibatch 52...\n",
      "\t (mb: 52) evaluating fgsm8...\n",
      "\t (mb: 52) evaluating pgd4...\n",
      "\t (mb: 52) evaluating pgd8...\n",
      "\t (mb: 52) evaluating ground...\n",
      "Starting minibatch 53...\n",
      "\t (mb: 53) evaluating fgsm8...\n",
      "\t (mb: 53) evaluating pgd4...\n",
      "\t (mb: 53) evaluating pgd8...\n",
      "\t (mb: 53) evaluating ground...\n",
      "Starting minibatch 54...\n",
      "\t (mb: 54) evaluating fgsm8...\n",
      "\t (mb: 54) evaluating pgd4...\n",
      "\t (mb: 54) evaluating pgd8...\n",
      "\t (mb: 54) evaluating ground...\n",
      "Starting minibatch 55...\n",
      "\t (mb: 55) evaluating fgsm8...\n",
      "\t (mb: 55) evaluating pgd4...\n",
      "\t (mb: 55) evaluating pgd8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (mb: 55) evaluating ground...\n",
      "Starting minibatch 56...\n",
      "\t (mb: 56) evaluating fgsm8...\n",
      "\t (mb: 56) evaluating pgd4...\n",
      "\t (mb: 56) evaluating pgd8...\n",
      "\t (mb: 56) evaluating ground...\n",
      "Starting minibatch 57...\n",
      "\t (mb: 57) evaluating fgsm8...\n",
      "\t (mb: 57) evaluating pgd4...\n",
      "\t (mb: 57) evaluating pgd8...\n",
      "\t (mb: 57) evaluating ground...\n",
      "Starting minibatch 58...\n",
      "\t (mb: 58) evaluating fgsm8...\n",
      "\t (mb: 58) evaluating pgd4...\n",
      "\t (mb: 58) evaluating pgd8...\n",
      "\t (mb: 58) evaluating ground...\n",
      "Starting minibatch 59...\n",
      "\t (mb: 59) evaluating fgsm8...\n",
      "\t (mb: 59) evaluating pgd4...\n",
      "\t (mb: 59) evaluating pgd8...\n",
      "\t (mb: 59) evaluating ground...\n",
      "Starting minibatch 60...\n",
      "\t (mb: 60) evaluating fgsm8...\n",
      "\t (mb: 60) evaluating pgd4...\n",
      "\t (mb: 60) evaluating pgd8...\n",
      "\t (mb: 60) evaluating ground...\n",
      "Starting minibatch 61...\n",
      "\t (mb: 61) evaluating fgsm8...\n",
      "\t (mb: 61) evaluating pgd4...\n",
      "\t (mb: 61) evaluating pgd8...\n",
      "\t (mb: 61) evaluating ground...\n",
      "Starting minibatch 62...\n",
      "\t (mb: 62) evaluating fgsm8...\n",
      "\t (mb: 62) evaluating pgd4...\n",
      "\t (mb: 62) evaluating pgd8...\n",
      "\t (mb: 62) evaluating ground...\n",
      "Starting minibatch 63...\n",
      "\t (mb: 63) evaluating fgsm8...\n",
      "\t (mb: 63) evaluating pgd4...\n",
      "\t (mb: 63) evaluating pgd8...\n",
      "\t (mb: 63) evaluating ground...\n",
      "Starting minibatch 64...\n",
      "\t (mb: 64) evaluating fgsm8...\n",
      "\t (mb: 64) evaluating pgd4...\n",
      "\t (mb: 64) evaluating pgd8...\n",
      "\t (mb: 64) evaluating ground...\n",
      "Starting minibatch 65...\n",
      "\t (mb: 65) evaluating fgsm8...\n",
      "\t (mb: 65) evaluating pgd4...\n",
      "\t (mb: 65) evaluating pgd8...\n",
      "\t (mb: 65) evaluating ground...\n",
      "Starting minibatch 66...\n",
      "\t (mb: 66) evaluating fgsm8...\n",
      "\t (mb: 66) evaluating pgd4...\n",
      "\t (mb: 66) evaluating pgd8...\n",
      "\t (mb: 66) evaluating ground...\n",
      "Starting minibatch 67...\n",
      "\t (mb: 67) evaluating fgsm8...\n",
      "\t (mb: 67) evaluating pgd4...\n",
      "\t (mb: 67) evaluating pgd8...\n",
      "\t (mb: 67) evaluating ground...\n",
      "Starting minibatch 68...\n",
      "\t (mb: 68) evaluating fgsm8...\n",
      "\t (mb: 68) evaluating pgd4...\n",
      "\t (mb: 68) evaluating pgd8...\n",
      "\t (mb: 68) evaluating ground...\n",
      "Starting minibatch 69...\n",
      "\t (mb: 69) evaluating fgsm8...\n",
      "\t (mb: 69) evaluating pgd4...\n",
      "\t (mb: 69) evaluating pgd8...\n",
      "\t (mb: 69) evaluating ground...\n",
      "Starting minibatch 70...\n",
      "\t (mb: 70) evaluating fgsm8...\n",
      "\t (mb: 70) evaluating pgd4...\n",
      "\t (mb: 70) evaluating pgd8...\n",
      "\t (mb: 70) evaluating ground...\n",
      "Starting minibatch 71...\n",
      "\t (mb: 71) evaluating fgsm8...\n",
      "\t (mb: 71) evaluating pgd4...\n",
      "\t (mb: 71) evaluating pgd8...\n",
      "\t (mb: 71) evaluating ground...\n",
      "Starting minibatch 72...\n",
      "\t (mb: 72) evaluating fgsm8...\n",
      "\t (mb: 72) evaluating pgd4...\n",
      "\t (mb: 72) evaluating pgd8...\n",
      "\t (mb: 72) evaluating ground...\n",
      "Starting minibatch 73...\n",
      "\t (mb: 73) evaluating fgsm8...\n",
      "\t (mb: 73) evaluating pgd4...\n",
      "\t (mb: 73) evaluating pgd8...\n",
      "\t (mb: 73) evaluating ground...\n",
      "Starting minibatch 74...\n",
      "\t (mb: 74) evaluating fgsm8...\n",
      "\t (mb: 74) evaluating pgd4...\n",
      "\t (mb: 74) evaluating pgd8...\n",
      "\t (mb: 74) evaluating ground...\n",
      "Starting minibatch 75...\n",
      "\t (mb: 75) evaluating fgsm8...\n",
      "\t (mb: 75) evaluating pgd4...\n",
      "\t (mb: 75) evaluating pgd8...\n",
      "\t (mb: 75) evaluating ground...\n",
      "Starting minibatch 76...\n",
      "\t (mb: 76) evaluating fgsm8...\n",
      "\t (mb: 76) evaluating pgd4...\n",
      "\t (mb: 76) evaluating pgd8...\n",
      "\t (mb: 76) evaluating ground...\n",
      "Starting minibatch 77...\n",
      "\t (mb: 77) evaluating fgsm8...\n",
      "\t (mb: 77) evaluating pgd4...\n",
      "\t (mb: 77) evaluating pgd8...\n",
      "\t (mb: 77) evaluating ground...\n",
      "Starting minibatch 78...\n",
      "\t (mb: 78) evaluating fgsm8...\n",
      "\t (mb: 78) evaluating pgd4...\n",
      "\t (mb: 78) evaluating pgd8...\n",
      "\t (mb: 78) evaluating ground...\n"
     ]
    }
   ],
   "source": [
    "# And now let's incorporate this into our to_eval_dict\n",
    "new_to_eval_dict = {'avg_successful_linf': avg_successful_linf}\n",
    "\n",
    "# And make some new EvaluationResult objects\n",
    "new_fgsm8_eval = adveval.EvaluationResult(fgsm8_attack_params, \n",
    "                                          to_eval=new_to_eval_dict)\n",
    "\n",
    "new_pgd4_eval = adveval.EvaluationResult(pgd4_attack_params, \n",
    "                                         to_eval=new_to_eval_dict)\n",
    "\n",
    "new_pgd8_eval = adveval.EvaluationResult(pgd8_attack_params, \n",
    "                                         to_eval=new_to_eval_dict)\n",
    "\n",
    "new_ensemble_in = {'fgsm8': new_fgsm8_eval, \n",
    "                   'pgd4': new_pgd4_eval, \n",
    "                   'pgd8': new_pgd8_eval}\n",
    "\n",
    "# And run through the evaluation \n",
    "new_ensemble_out = adv_eval_object.evaluate_ensemble(cifar_valset, new_ensemble_in,\n",
    "                                                     verbose=True,\n",
    "                                                     num_minibatches=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~ avg_successful_linf ~~~~~~~~~~\n",
      "fgsm8   :  8.000006060446461\n",
      "pgd4    :  4.000008220257966\n",
      "pgd8    :  4.000008220257966\n"
     ]
    }
   ],
   "source": [
    "# Finally we can take a look at the evaluation that we've monkeypatched in\n",
    "pretty_printer(new_ensemble_out, 'avg_successful_linf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xentropy_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1e7dfaf53186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxentropy_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xentropy_eval' is not defined"
     ]
    }
   ],
   "source": [
    "callable(xentropy_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorials for `mister_ed`. If there's anything that's confusing, or any features that you want supported that aren't ready out of the box, please feel free to open an issue on the main github repo and I'll do my best to catering to user requests. \n",
    "\n",
    "(also let me know about any bugs!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
